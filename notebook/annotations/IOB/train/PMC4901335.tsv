On	O
the	O
Computational	O
Power	O
of	O
Spiking	O
Neural	O
P	O
Systems	O
with	O
Self	O
-	O
Organization	O

Neural	O
-	O
like	O
computing	O
models	O
are	O
versatile	O
computing	O
mechanisms	O
in	O
the	O
field	O
of	O
artificial	O
intelligence	O
.	O

Spiking	O
neural	O
P	O
systems	O
(	O
SN	O
P	O
systems	O
for	O
short	O
)	O
are	O
one	O
of	O
the	O
recently	O
developed	O
spiking	O
neural	O
network	O
models	O
inspired	O
by	O
the	O
way	O
neurons	O
communicate	O
.	O

The	O
communications	O
among	O
neurons	O
are	O
essentially	O
achieved	O
by	O
spikes	O
,	O
i	O
.	O
e	O
.	O
short	O
electrical	O
pulses	O
.	O

In	O
terms	O
of	O
motivation	O
,	O
SN	O
P	O
systems	O
fall	O
into	O
the	O
third	O
generation	O
of	O
neural	O
network	O
models	O
.	O

In	O
this	O
study	O
,	O
a	O
novel	O
variant	O
of	O
SN	O
P	O
systems	O
,	O
namely	O
SN	O
P	O
systems	O
with	O
self	O
-	O
organization	O
,	O
is	O
introduced	O
,	O
and	O
the	O
computational	O
power	O
of	O
the	O
system	O
is	O
investigated	O
and	O
evaluated	O
.	O

It	O
is	O
proved	O
that	O
SN	O
P	O
systems	O
with	O
self	O
-	O
organization	O
are	O
capable	O
of	O
computing	O
and	O
accept	O
the	O
family	O
of	O
sets	O
of	O
Turing	O
computable	O
natural	O
numbers	O
.	O

Moreover	O
,	O
with	O
87	O
neurons	O
the	O
system	O
can	O
compute	O
any	O
Turing	O
computable	O
recursive	O
function	O
,	O
thus	O
achieves	O
Turing	O
universality	O
.	O

These	O
results	O
demonstrate	O
promising	O
initiatives	O
to	O
solve	O
an	O
open	O
problem	O
arisen	O
by	O
Gh	O
Păun	O
.	O

In	O
the	O
central	O
nervous	O
system	O
,	O
there	O
are	O
abundant	O
amount	O
of	O
computational	O
intelligence	O
precipitated	O
throughout	O
millions	O
of	O
years	O
of	O
evolution	O
.	O

The	O
computational	O
intelligence	O
has	O
provided	O
plenty	O
of	O
inspirations	O
to	O
construct	O
powerful	O
computing	O
models	O
and	O
algorithms123	O
.	O

Neural	O
-	O
like	O
computing	O
models	O
are	O
a	O
class	O
of	O
powerful	O
models	O
inspired	O
by	O
the	O
way	O
how	O
neurons	O
communicate	O
.	O

The	O
communication	O
among	O
neurons	O
is	O
essentially	O
achieved	O
by	O
spikes	O
,	O
i	O
.	O
e	O
.	O
short	O
electrical	O
pulses	O
.	O

The	O
biological	O
phenomenon	O
has	O
been	O
intensively	O
investigated	O
in	O
the	O
field	O
of	O
neural	O
computation4	O
.	O

Using	O
different	O
mathematic	O
approaches	O
to	O
describe	O
neural	O
spiking	O
behaviours	O
,	O
various	O
neural	O
-	O
like	O
computing	O
models	O
have	O
been	O
proposed	O
,	O
such	O
as	O
artificial	O
neural	O
networks5	O
and	O
spiking	O
neural	O
networks6	O
.	O

In	O
the	O
field	O
of	O
membrane	O
computing	O
,	O
a	O
kind	O
of	O
distributed	O
and	O
parallel	O
neural	O
-	O
like	O
computation	O
model	O
,	O
named	O
spiking	O
neural	O
P	O
systems	O
(	O
SN	O
P	O
systems	O
),	O
were	O
proposed	O
in	O
20067	O
.	O

SN	O
P	O
systems	O
are	O
widely	O
considered	O
as	O
a	O
promising	O
variant	O
of	O
the	O
third	O
generation	O
of	O
neural	O
network	O
models8	O
.	O

Generally	O
,	O
an	O
SN	O
P	O
system	O
can	O
be	O
represented	O
by	O
a	O
directed	O
graph	O
,	O
where	O
neurons	O
are	O
placed	O
in	O
nodes	O
and	O
the	O
synapses	O
are	O
denoted	O
using	O
arcs	O
.	O

Every	O
neuron	O
can	O
contain	O
a	O
number	O
of	O
spikes	O
and	O
a	O
set	O
of	O
firing	O
(	O
or	O
spiking	O
)	O
rules	O
.	O

Following	O
the	O
firing	O
rules	O
,	O
a	O
neuron	O
can	O
send	O
information	O
encoded	O
in	O
spikes	O
to	O
other	O
neurons	O
.	O

Input	O
neurons	O
read	O
spikes	O
from	O
the	O
environment	O
,	O
and	O
output	O
neurons	O
emit	O
spikes	O
into	O
the	O
environment	O
.	O

The	O
computation	O
result	O
can	O
be	O
embodied	O
in	O
various	O
ways	O
.	O

One	O
of	O
the	O
common	O
approaches	O
is	O
the	O
time	O
elapsed	O
between	O
the	O
first	O
two	O
consecutive	O
spikes	O
sent	O
into	O
the	O
environment910	O
and	O
the	O
total	O
number	O
of	O
spikes	O
emitted	O
into	O
the	O
environment111213	O
.	O

For	O
the	O
past	O
decade	O
,	O
there	O
have	O
been	O
quite	O
a	O
few	O
research	O
efforts	O
put	O
forward	O
to	O
SN	O
P	O
systems	O
.	O

Notably	O
,	O
SN	O
P	O
systems	O
can	O
generate	O
and	O
accept	O
the	O
sets	O
of	O
Turing	O
computable	O
natural	O
numbers14	O
,	O
generate	O
the	O
recursively	O
enumerable	O
languages1516	O
and	O
compute	O
the	O
sets	O
of	O
Turing	O
computable	O
functions17	O
.	O

Inspired	O
by	O
different	O
biological	O
phenomena	O
and	O
mathematical	O
motivations	O
,	O
lots	O
of	O
variants	O
of	O
SN	O
P	O
systems	O
have	O
been	O
proposed	O
,	O
such	O
as	O
SN	O
P	O
systems	O
with	O
anti	O
-	O
spikes1819	O
,	O
SN	O
P	O
systems	O
with	O
weight20	O
,	O
SN	O
P	O
systems	O
with	O
astrocyte21	O
,	O
homogenous	O
SN	O
P	O
systems2223	O
,	O
SN	O
P	O
systems	O
with	O
threshold24	O
,	O
fuzzy	O
SN	O
P	O
systems2526	O
,	O
sequential	O
SN	O
P	O
systems27	O
,	O
SN	O
P	O
systems	O
with	O
rules	O
on	O
synapses28	O
,	O
SN	O
P	O
systems	O
with	O
structural	O
plasticity29	O
.	O

For	O
applications	O
,	O
SN	O
P	O
systems	O
are	O
used	O
to	O
design	O
logic	O
gates	O
,	O
logic	O
circuites30	O
and	O
operating	O
systems31	O
,	O
perform	O
basic	O
arithmetic	O
operations3233	O
,	O
solve	O
combinatorial	O
optimization	O
problems34	O
,	O
diagnose	O
fault	O
of	O
electric	O
power	O
systems35	O
.	O

SN	O
P	O
systems	O
are	O
known	O
as	O
a	O
class	O
of	O
neural	O
-	O
like	O
computing	O
models	O
under	O
the	O
framework	O
of	O
membrane	O
computing36	O
.	O

Spiking	O
neural	O
network	O
(	O
shortly	O
named	O
SNN	O
)	O
is	O
a	O
well	O
known	O
candidate	O
of	O
siking	O
neural	O
network	O
models37	O
,	O
which	O
incorporates	O
the	O
concept	O
of	O
time	O
into	O
their	O
operating	O
model	O
,	O
besides	O
neuronal	O
and	O
synaptic	O
state	O
in	O
general	O
artificial	O
neural	O
networks	O
,	O
The	O
neuron	O
in	O
SNN	O
cannot	O
fire	O
at	O
each	O
propagation	O
cycle	O
,	O
but	O
only	O
when	O
a	O
membrane	O
potential	O
reaches	O
a	O
specific	O
value	O
.	O

When	O
a	O
neuron	O
fires	O
,	O
it	O
generates	O
a	O
signal	O
which	O
travels	O
to	O
other	O
neurons	O
which	O
,	O
in	O
turn	O
,	O
increase	O
or	O
decrease	O
their	O
potentials	O
in	O
accordance	O
with	O
this	O
signal	O
.	O

In	O
SN	O
P	O
systems	O
,	O
spiking	O
rules	O
,	O
denoted	O
by	O
formal	O
production	O
in	O
grammar	O
theory	O
of	O
formal	O
languages	O
,	O
is	O
used	O
to	O
describe	O
the	O
neuron	O
'	O
s	O
spiking	O
behaviour	O
,	O
which	O
determine	O
the	O
conditions	O
of	O
triggering	O
spiking	O
,	O
the	O
number	O
of	O
spikes	O
consumed	O
,	O
and	O
the	O
number	O
of	O
spikes	O
emitting	O
to	O
the	O
neighboring	O
neurons	O
.	O

The	O
spikes	O
from	O
different	O
neurons	O
can	O
be	O
accumulated	O
in	O
the	O
target	O
neuron	O
for	O
further	O
spiking	O
.	O

In	O
terms	O
of	O
motivation	O
of	O
models	O
,	O
SN	O
P	O
systems	O
also	O
fall	O
into	O
the	O
spiking	O
neural	O
network	O
models	O
,	O
i	O
.	O
e	O
.,	O
the	O
third	O
generation	O
of	O
neural	O
network	O
models	O
.	O

Since	O
SN	O
P	O
systems	O
have	O
more	O
fundamental	O
data	O
structure	O
(	O
spike	O
trains	O
,	O
i	O
.	O
e	O
.,	O
binary	O
strings	O
),	O
it	O
performs	O
well	O
in	O
achieving	O
significant	O
computation	O
power	O
with	O
using	O
a	O
small	O
number	O
of	O
units	O
(	O
neurons	O
).	O

It	O
was	O
proved	O
by	O
Gh	O
Păun	O
that	O
49	O
neurons	O
are	O
sufficient	O
for	O
SN	O
P	O
systems	O
to	O
achieve	O
Turing	O
universality	O
.	O

But	O
,	O
for	O
conventional	O
artificial	O
neural	O
networks	O
,	O
it	O
was	O
shown	O
that	O
886	O
sigmoid	O
function	O
based	O
processors	O
are	O
needed	O
to	O
achieve	O
Turing	O
universality38	O
.	O

In	O
the	O
nervous	O
system	O
,	O
synaptic	O
plasticity	O
forms	O
the	O
cell	O
assemblies	O
with	O
the	O
self	O
-	O
organization	O
of	O
neurons	O
,	O
which	O
induces	O
ordered	O
or	O
even	O
synchronized	O
neural	O
dynamics	O
replicating	O
basic	O
processes	O
of	O
long	O
-	O
term	O
memory3940	O
.	O

The	O
self	O
-	O
organizing	O
principle	O
in	O
the	O
developing	O
nervous	O
system	O
and	O
its	O
importance	O
for	O
preserving	O
and	O
continuing	O
neural	O
system	O
development	O
provide	O
us	O
insights	O
on	O
how	O
neural	O
-	O
like	O
networks	O
might	O
be	O
reorganized	O
and	O
configured	O
in	O
response	O
to	O
environment	O
changes	O
.	O

Enlightened	O
by	O
the	O
biological	O
fact	O
,	O
self	O
-	O
organizing	O
artificial	O
neural	O
networks	O
with	O
unsupervised	O
and	O
supervised	O
learning	O
have	O
been	O
proposed	O
and	O
gain	O
their	O
popularity	O
for	O
visualisation	O
and	O
classification4142	O
.	O

It	O
is	O
still	O
an	O
open	O
problem	O
as	O
formulated	O
by	O
Gh	O
Păun	O
in	O
ref	O
.	O
43	O
,	O
to	O
construct	O
SN	O
P	O
systems	O
with	O
self	O
-	O
organization	O
and	O
to	O
use	O
the	O
system	O
to	O
perform	O
possible	O
computer	O
vision	O
and	O
pattern	O
recognition	O
tasks	O
.	O

Results	O

In	O
this	O
research	O
,	O
a	O
novel	O
variant	O
of	O
SN	O
P	O
systems	O
,	O
namely	O
SN	O
P	O
systems	O
with	O
self	O
-	O
organization	O
,	O
is	O
proposed	O
and	O
developed	O
.	O

The	O
system	O
initially	O
has	O
no	O
synapse	O
,	O
but	O
the	O
synapses	O
can	O
be	O
dynamically	O
formed	O
during	O
the	O
computation	O
,	O
which	O
exhibits	O
the	O
self	O
-	O
organization	O
behaviour	O
.	O

In	O
the	O
system	O
,	O
creation	O
and	O
deletion	O
rules	O
are	O
used	O
to	O
create	O
and	O
delete	O
synapses	O
.	O

The	O
applications	O
of	O
synapse	O
creation	O
and	O
deletion	O
rules	O
are	O
controlled	O
by	O
the	O
states	O
of	O
the	O
involved	O
neurons	O
,	O
i	O
.	O
e	O
.,	O
the	O
number	O
of	O
spikes	O
contained	O
in	O
the	O
neurons	O
.	O

The	O
computational	O
power	O
of	O
the	O
system	O
is	O
investigated	O
as	O
well	O
.	O

As	O
a	O
result	O
,	O
it	O
demonstrates	O
that	O
SN	O
P	O
systems	O
with	O
self	O
-	O
organization	O
can	O
compute	O
and	O
accept	O
any	O
set	O
of	O
Turing	O
computable	O
natural	O
numbers	O
.	O

Moreover	O
,	O
with	O
87	O
neurons	O
,	O
the	O
system	O
can	O
compute	O
any	O
Turing	O
computable	O
recursive	O
function	O
,	O
ergo	O
achieves	O
Turing	O
universality	O
.	O

Before	O
stating	O
the	O
results	O
in	O
mathematical	O
forms	O
,	O
some	O
notations	O
should	O
be	O
introduced	O
.	O
NmSPSOall	O
(	O
creh	O
,	O
delg	O
,	O
ruler	O
)	O
(	O
resp	O
.	O
NmSPSOacc	O
(	O
creh	O
′,	O
delg	O
′,	O
ruler	O
′))	O
denotes	O
the	O
family	O
of	O
sets	O
of	O
numbers	O
computed	O
(	O
resp	O
.	O

accepted	O
)	O
by	O
SN	O
P	O
systems	O
with	O
self	O
-	O
organization	O
of	O
degree	O
m	O
,	O
where	O
h	O
(	O
resp	O
.	O
h	O
′)	O
indicates	O
the	O
maximal	O
number	O
of	O
synapses	O
that	O
can	O
be	O
created	O
using	O
a	O
synapse	O
creation	O
rule	O
,	O
g	O
(	O
resp	O
.	O
g	O
′)	O
is	O
the	O
maximal	O
number	O
of	O
synapses	O
that	O
can	O
be	O
deleted	O
by	O
using	O
a	O
synapse	O
deletion	O
rule	O
,	O
r	O
(	O
resp	O
.	O
r	O
′)	O
is	O
the	O
maximal	O
number	O
of	O
rules	O
in	O
each	O
neuron	O
,	O
and	O
the	O
subscript	O
all	O
indicates	O
the	O
computation	O
result	O
is	O
encoded	O
by	O
the	O
number	O
of	O
spikes	O
emitted	O
into	O
the	O
environment	O
(	O
resp	O
.	O
the	O
subscript	O
acc	O
indicates	O
the	O
system	O
works	O
in	O
the	O
accepting	O
mode	O
).	O

If	O
the	O
parameters	O
are	O
not	O
bounded	O
,	O
i	O
.	O
e	O
.,	O
there	O
is	O
no	O
limit	O
imposed	O
on	O
them	O
,	O
then	O
they	O
are	O
replaced	O
with	O
*.	O
NRE	O
denotes	O
the	O
family	O
of	O
Turing	O
computable	O
sets	O
of	O
numbers44	O
.	O

The	O
main	O
results	O
of	O
this	O
work	O
can	O
be	O
mathematically	O
depicted	O
by	O
the	O
following	O
theorems	O
.	O

Theorem	O
1	O
.	O
N	O
*	O
SPSOall	O
(	O
cre	O
*,	O
del	O
*,	O
rule5	O
)	O
=	O
NRE	O
.	O

Theorem	O
2	O
.	O
N	O
*	O
SPSOacc	O
(	O
cre	O
*,	O
del	O
*,	O
rule5	O
)	O
=	O
NRE	O
.	O

Theorem	O
3	O
.	O
There	O
is	O
a	O
universal	O
SN	O
P	O
system	O
with	O
self	O
-	O
organization	O
having	O
87	O
neurons	O
for	O
computing	O
functions	O
.	O

These	O
results	O
show	O
that	O
SN	O
P	O
systems	O
with	O
self	O
-	O
organization	O
are	O
powerful	O
computing	O
models	O
,	O
i	O
.	O
e	O
.,	O
they	O
are	O
capable	O
of	O
doing	O
what	O
Turing	O
machine	O
can	O
do	O
.	O

Also	O
,	O
they	O
provide	O
potential	O
and	O
theoretical	O
feasibility	O
of	O
using	O
SN	O
P	O
systems	O
to	O
solve	O
real	O
-	O
life	O
problems	O
,	O
such	O
as	O
pattern	O
recognition	O
and	O
classification	O
.	O

In	O
SN	O
P	O
system	O
with	O
self	O
-	O
organization	O
,	O
it	O
has	O
no	O
initially	O
designed	O
synapses	O
.	O

The	O
synapses	O
can	O
be	O
created	O
or	O
deleted	O
according	O
to	O
the	O
information	O
contained	O
in	O
involved	O
neurons	O
during	O
the	O
computation	O
.	O

In	O
previous	O
work	O
,	O
it	O
was	O
found	O
that	O
the	O
information	O
diversing	O
ability	O
of	O
synapses	O
had	O
some	O
programable	O
feature	O
for	O
SN	O
P	O
systems	O
,	O
but	O
the	O
computation	O
power	O
of	O
SN	O
P	O
systems	O
without	O
initial	O
synapses	O
is	O
an	O
open	O
problem	O
.	O

Although	O
this	O
is	O
not	O
the	O
first	O
time	O
the	O
feature	O
of	O
creating	O
or	O
deleting	O
synapses	O
investigated	O
in	O
SN	O
P	O
systems	O
,	O
see	O
e	O
.	O
g	O
.	O
SN	O
P	O
systems	O
with	O
structural	O
plasticity	O
,	O
it	O
is	O
quite	O
the	O
first	O
attempt	O
to	O
construct	O
SN	O
P	O
systems	O
has	O
no	O
initial	O
synapses	O
.	O

Methods	O

In	O
this	O
section	O
,	O
it	O
starts	O
by	O
the	O
mathematical	O
definition	O
of	O
SN	O
P	O
system	O
with	O
self	O
-	O
organization	O
,	O
and	O
then	O
the	O
computation	O
power	O
of	O
SN	O
P	O
systems	O
with	O
self	O
-	O
organization	O
is	O
investigated	O
as	O
number	O
generator	O
,	O
acceptor	O
and	O
function	O
computing	O
devices	O
.	O

It	O
is	O
proved	O
in	O
constructive	O
ways	O
that	O
SN	O
P	O
systems	O
with	O
self	O
-	O
organization	O
can	O
compute	O
and	O
accept	O
the	O
family	O
of	O
sets	O
of	O
Turing	O
computable	O
natural	O
numbers	O
.	O

With	O
87	O
neurons	O
,	O
such	O
system	O
can	O
compute	O
any	O
Turing	O
computable	O
recursive	O
function	O
.	O

Spiking	O
Neural	O
P	O
Systems	O
with	O
Self	O
-	O
Organization	O

Before	O
introducing	O
the	O
definition	O
of	O
SN	O
P	O
system	O
with	O
self	O
-	O
organization	O
,	O
some	O
prerequisites	O
of	O
basic	O
concepts	O
of	O
formal	O
language	O
theory45	O
are	O
recalled	O
.	O

For	O
an	O
alphabet	O
V	O
,	O
V	O
*	O
denotes	O
the	O
set	O
of	O
all	O
finite	O
strings	O
of	O
symbols	O
from	O
V	O
,	O
the	O
empty	O
string	O
is	O
denoted	O
by	O
λ	O
,	O
and	O
the	O
set	O
of	O
all	O
nonempty	O
strings	O
over	O
V	O
is	O
denoted	O
by	O
V	O
+.	O

When	O
V	O
=	O
{	O
a	O
}	O
is	O
a	O
singleton	O
,	O
then	O
we	O
write	O
simply	O
a	O
*	O
and	O
a	O
+	O
instead	O
of	O
{	O
a	O
}*,	O
{	O
a	O
}+.	O

A	O
regular	O
expression	O
over	O
an	O
alphabet	O
V	O
is	O
defined	O
as	O
follows	O
:	O
(	O
1	O
)	O
λ	O
and	O
each	O
a	O
∈	O
V	O
is	O
a	O
regular	O
expression	O
;	O
(	O
2	O
)	O
if	O
E1	O
and	O
E2	O
are	O
regular	O
expressions	O
over	O
V	O
,	O
then	O
(	O
E1	O
)(	O
E2	O
),	O
(	O
E1	O
)	O
∪	O
(	O
E2	O
),	O
and	O
(	O
E1	O
)+	O
are	O
regular	O
expressions	O
over	O
V	O
;	O
(	O
3	O
)	O
nothing	O
else	O
is	O
a	O
regular	O
expression	O
over	O
V	O
.	O

For	O
each	O
regular	O
expression	O
E	O
,	O
a	O
language	O
L	O
(	O
E	O
)	O
is	O
associated	O
,	O
defined	O
in	O
the	O
following	O
way	O
:	O
(	O
1	O
)	O
L	O
(	O
λ	O
)	O
=	O
{	O
λ	O
}	O
and	O
L	O
(	O
a	O
)	O
=	O
{	O
a	O
},	O
for	O
all	O
a	O
∈	O
V	O
,	O
(	O
2	O
)	O
L	O
((	O
E1	O
)∪(	O
E2	O
))	O
=	O
L	O
(	O
E1	O
)	O
∪	O
L	O
(	O
E2	O
),	O
L	O
((	O
E1	O
)(	O
E2	O
))	O
=	O
L	O
(	O
E1	O
)	O
L	O
(	O
E2	O
)	O
and	O
L	O
((	O
E1	O
)+)	O
=	O
(	O
L	O
(	O
E1	O
))+	O
for	O
all	O
regular	O
expressions	O
E1	O
,	O
E2	O
over	O
V	O
.	O

Unnecessary	O
parentheses	O
can	O
be	O
omitted	O
when	O
writing	O
a	O
regular	O
expression	O
,	O
and	O
(	O
E	O
)+	O
∪	O
{	O
λ	O
}	O
can	O
also	O
be	O
written	O
as	O
E	O
*.	O

By	O
NRE	O
we	O
denote	O
the	O
family	O
of	O
Turing	O
computable	O
sets	O
of	O
numbers	O
.	O

(	O
NRE	O
is	O
the	O
family	O
of	O
length	O
sets	O
of	O
recursively	O
enumerable	O
languages	O
–	O
those	O
recognized	O
by	O
Turing	O
machines	O
).	O

An	O
SN	O
P	O
system	O
with	O
self	O
-	O
organization	O
of	O
degree	O
m	O
≥	O
1	O
is	O
a	O
construct	O
of	O
the	O
form	O


where	O
O	O
=	O
{	O
a	O
}	O
is	O
a	O
singleton	O
,	O
where	O
a	O
is	O
called	O
the	O
spike	O
;	O
σ1	O
,	O
σ2	O
,	O
…,	O
σm	O
are	O
neurons	O
of	O
the	O
form	O
σi	O
=	O
(	O
ni	O
,	O
Ri	O
)	O
with	O
1	O
≤	O
i	O
≤	O
m	O
,	O
where	O

–	O
is	O
the	O
initial	O
number	O
of	O
spikes	O
contained	O
in	O
neuron	O
σi	O
;	O

–	O
Ri	O
is	O
a	O
finite	O
set	O
of	O
rules	O
in	O
neuron	O
σi	O
of	O
the	O
following	O
three	O
forms	O
:	O
spiking	O
rule	O
:	O
E	O
/	O
ac	O
→	O
ap	O
;	O
d	O
,	O
where	O
E	O
is	O
a	O
regular	O
expression	O
over	O
O	O
,	O
d	O
≥	O
0	O
and	O
c	O
≥	O
p	O
≥	O
0	O
;	O
synapse	O
creation	O
rule	O
:	O
E	O
′/	O
ac	O
′	O
→	O
+(	O
ap	O
′,	O
cre	O
(	O
i	O
)),	O
where	O
E	O
′	O
is	O
a	O
regular	O
expression	O
over	O
O	O
,	O
cre	O
(	O
i	O
)	O
⊆	O
{	O
σ1	O
,	O
σ2	O
,	O
…,	O
σm	O
}/{	O
σi	O
}	O
and	O
c	O
′	O
≥	O
p	O
′	O
>	O
1	O
;	O
synapse	O
deletion	O
rule	O
:	O
E	O
″/	O
ac	O
″	O
→	O
−(	O
λ	O
,	O
del	O
(	O
i	O
)),	O
where	O
E	O
″	O
is	O
a	O
regular	O
expression	O
over	O
O	O
,	O
del	O
(	O
i	O
)	O
⊆	O
{	O
σ1	O
,	O
σ2	O
,	O
…,	O
σm	O
}/{	O
σi	O
}	O
and	O
c	O
″	O
≥	O
1	O
;	O

is	O
the	O
initial	O
set	O
of	O
synapses	O
,	O
which	O
means	O
no	O
synapse	O
is	O
initially	O
set	O
;	O
at	O
any	O
moment	O
t	O
,	O
the	O
set	O
of	O
synapses	O
is	O
denoted	O
by	O
synt	O
⊆	O
{	O
1	O
,	O
2	O
,	O
…,	O
m	O
}	O
×	O
{	O
1	O
,	O
2	O
,	O
…,	O
m	O
}.	O
in	O
,	O
out	O
∈	O
{	O
1	O
,	O
2	O
,	O
…,	O
m	O
}	O
indicates	O
the	O
input	O
and	O
output	O
neuron	O
,	O
respectively	O
.	O

A	O
spiking	O
rule	O
of	O
the	O
form	O
E	O
/	O
ac	O
→	O
ap	O
;	O
d	O
is	O
applied	O
as	O
follows	O
.	O

If	O
neuron	O
σi	O
contains	O
k	O
spikes	O
,	O
and	O
ak	O
∈	O
L	O
(	O
E	O
),	O
k	O
≥	O
c	O
,	O
then	O
rule	O
E	O
/	O
ac	O
→	O
ap	O
;	O
d	O
∈	O
Ri	O
can	O
be	O
applied	O
.	O

It	O
means	O
that	O
c	O
spikes	O
are	O
consumed	O
and	O
removed	O
from	O
neuron	O
σi	O
,	O
i	O
.	O
e	O
.,	O
k	O
−	O
c	O
spikes	O
are	O
remained	O
,	O
while	O
the	O
neuron	O
emits	O
p	O
spikes	O
to	O
its	O
neighboring	O
neurons	O
after	O
d	O
steps	O
.	O

(	O
It	O
is	O
a	O
common	O
practice	O
in	O
membrane	O
computing	O
to	O
have	O
a	O
global	O
clock	O
defined	O
.	O

The	O
clock	O
is	O
used	O
to	O
mark	O
the	O
time	O
of	O
the	O
whole	O
system	O
and	O
ensure	O
the	O
system	O
synchronization	O
.)	O
If	O
d	O
=	O
0	O
,	O
then	O
the	O
p	O
spikes	O
are	O
emitted	O
out	O
immediately	O
,	O
if	O
d	O
=	O
1	O
,	O
then	O
the	O
p	O
spikes	O
are	O
emitted	O
in	O
the	O
next	O
step	O
,	O
etc	O
.	O

If	O
the	O
rule	O
is	O
used	O
in	O
step	O
t	O
and	O
d	O
≥	O
1	O
,	O
then	O
in	O
steps	O
t	O
,	O
t	O
+	O
1	O
,	O
...,	O
t	O
+	O
d	O
−	O
1	O
the	O
neuron	O
is	O
closed	O
(	O
this	O
corresponds	O
to	O
the	O
refractory	O
period	O
from	O
neurobiology	O
),	O
so	O
that	O
it	O
cannot	O
receive	O
new	O
spikes	O
(	O
if	O
a	O
neuron	O
tries	O
to	O
send	O
spikes	O
to	O
a	O
neuron	O
in	O
close	O
status	O
,	O
then	O
these	O
particular	O
spikes	O
will	O
be	O
lost	O
).	O

In	O
the	O
step	O
t	O
+	O
d	O
,	O
the	O
neuron	O
fires	O
and	O
regains	O
open	O
status	O
,	O
so	O
it	O
can	O
receive	O
spikes	O
(	O
which	O
can	O
be	O
used	O
starting	O
with	O
the	O
step	O
t	O
+	O
d	O
+	O
1	O
,	O
when	O
the	O
neuron	O
can	O
again	O
apply	O
rules	O
).	O

It	O
is	O
possible	O
that	O
p	O
is	O
associated	O
with	O
value	O
0	O
.	O

In	O
this	O
case	O
,	O
neuron	O
σi	O
consumes	O
c	O
spikes	O
without	O
emitting	O
any	O
spike	O
.	O

Spiking	O
rule	O
with	O
p	O
=	O
0	O
is	O
also	O
called	O
forgetting	O
rule	O
,	O
by	O
which	O
a	O
pre	O
-	O
defined	O
number	O
of	O
spikes	O
can	O
be	O
removed	O
out	O
of	O
the	O
neuron	O
.	O

If	O
E	O
=	O
ac	O
,	O
then	O
the	O
rule	O
can	O
be	O
written	O
in	O
the	O
simplified	O
form	O
ac	O
→	O
ap	O
;	O
d	O
,	O
and	O
if	O
d	O
=	O
0	O
,	O
then	O
the	O
rule	O
can	O
be	O
simply	O
written	O
as	O
E	O
/	O
ac	O
→	O
ap	O
.	O

Synapse	O
creation	O
and	O
deletion	O
rules	O
are	O
used	O
to	O
create	O
and	O
delete	O
synapses	O
during	O
the	O
computation	O
.	O

Synapse	O
creation	O
rule	O
E	O
′/	O
ac	O
′	O
→	O
+(	O
ap	O
′,	O
cre	O
(	O
i	O
))	O
is	O
applied	O
as	O
follows	O
.	O

If	O
neuron	O
σi	O
has	O
k	O
′	O
spikes	O
such	O
that	O
ak	O
′	O
∈	O
L	O
(	O
E	O
′),	O
k	O
′	O
≥	O
c	O
′,	O
then	O
the	O
synapse	O
creation	O
rule	O
is	O
applied	O
with	O
consuming	O
c	O
′	O
spikes	O
,	O
creating	O
synapses	O
to	O
connect	O
neuron	O
σi	O
to	O
each	O
neuron	O
in	O
cre	O
(	O
i	O
)	O
and	O
emitting	O
p	O
′	O
spikes	O
to	O
each	O
neuron	O
in	O
cre	O
(	O
i	O
).	O

If	O
neuron	O
σi	O
has	O
k	O
″	O
spikes	O
such	O
that	O
ak	O
″	O
∈	O
L	O
(	O
E	O
″)	O
and	O
k	O
″	O
≥	O
c	O
″,	O
then	O
synapse	O
deletion	O
rule	O
E	O
″/	O
ac	O
″	O
→	O
−(	O
λ	O
,	O
del	O
(	O
i	O
))	O
is	O
applied	O
,	O
removing	O
c	O
″	O
spikes	O
from	O
neuron	O
σi	O
and	O
deleting	O
all	O
the	O
synapses	O
connecting	O
neuron	O
σi	O
to	O
the	O
neurons	O
from	O
del	O
(	O
i	O
).	O

With	O
the	O
synapse	O
creation	O
and	O
deletion	O
rules	O
,	O
E	O
′	O
and	O
E	O
″	O
are	O
regular	O
expressions	O
over	O
O	O
=	O
{	O
a	O
},	O
which	O
regulate	O
the	O
application	O
of	O
synapse	O
creation	O
and	O
deletion	O
rules	O
.	O

This	O
means	O
that	O
synapse	O
creation	O
and	O
deletion	O
rules	O
can	O
be	O
used	O
if	O
and	O
only	O
if	O
the	O
neuron	O
contain	O
some	O
particular	O
numbers	O
of	O
spikes	O
,	O
i	O
.	O
e	O
.,	O
the	O
neuron	O
is	O
in	O
some	O
specific	O
states	O
.	O

With	O
the	O
applications	O
of	O
synapse	O
creation	O
and	O
deletion	O
rules	O
the	O
system	O
can	O
dynamically	O
rebuild	O
its	O
topological	O
structure	O
during	O
the	O
computation	O
,	O
which	O
is	O
herein	O
defined	O
as	O
self	O
-	O
organization	O
.	O

One	O
neuron	O
is	O
specified	O
as	O
the	O
input	O
neuron	O
,	O
through	O
which	O
the	O
system	O
can	O
read	O
spikes	O
from	O
the	O
environment	O
.	O

The	O
output	O
neuron	O
has	O
a	O
synapse	O
creation	O
rule	O
of	O
the	O
form	O
E	O
′/	O
ac	O
′	O
→	O
+(	O
ap	O
′,	O
{	O
0	O
}),	O
where	O
the	O
environment	O
is	O
labelled	O
by	O
0	O
.	O

By	O
using	O
the	O
rule	O
,	O
the	O
output	O
neuron	O
creates	O
a	O
synapse	O
pointing	O
to	O
the	O
environment	O
,	O
and	O
then	O
it	O
can	O
emit	O
spikes	O
into	O
the	O
environment	O
along	O
the	O
created	O
synapse	O
.	O

For	O
each	O
time	O
step	O
,	O
as	O
long	O
as	O
there	O
is	O
one	O
available	O
rule	O
in	O
Ri	O
,	O
neuron	O
σi	O
must	O
apply	O
the	O
rule	O
.	O

It	O
is	O
possible	O
that	O
there	O
are	O
more	O
than	O
one	O
rule	O
that	O
can	O
be	O
used	O
in	O
a	O
neuron	O
at	O
some	O
moment	O
,	O
since	O
spiking	O
rules	O
,	O
synapse	O
creation	O
rules	O
and	O
synapse	O
deletion	O
rules	O
may	O
be	O
associated	O
with	O
regular	O
languages	O
(	O
according	O
to	O
their	O
regular	O
expressions	O
).	O

In	O
this	O
case	O
,	O
the	O
neuron	O
will	O
non	O
-	O
deterministically	O
uses	O
one	O
of	O
the	O
enabled	O
rules	O
.	O

The	O
system	O
works	O
sequentially	O
in	O
each	O
neuron	O
(	O
at	O
most	O
one	O
rule	O
from	O
each	O
Ri	O
can	O
be	O
used	O
),	O
and	O
if	O
parallelism	O
is	O
designed	O
for	O
the	O
system	O
,	O
all	O
the	O
neurons	O
at	O
the	O
same	O
system	O
level	O
have	O
at	O
least	O
one	O
enabled	O
rule	O
activated	O
.	O

The	O
configuration	O
of	O
the	O
system	O
at	O
certain	O
moment	O
is	O
defined	O
by	O
three	O
major	O
factors	O
which	O
are	O
the	O
number	O
of	O
spikes	O
contained	O
in	O
each	O
neuron	O
,	O
the	O
number	O
of	O
steps	O
to	O
wait	O
until	O
it	O
becomes	O
open	O
and	O
the	O
current	O
set	O
of	O
synapses	O
.	O

With	O
the	O
notion	O
,	O
the	O
initial	O
configuration	O
of	O
the	O
system	O
is	O
〈	O
n1	O
/	O
0	O
,	O
n2	O
/	O
0	O
,	O
…,	O
nm	O
/	O
0	O
,	O
.	O

Using	O
the	O
spiking	O
,	O
forgetting	O
,	O
synapse	O
creation	O
and	O
deletion	O
rules	O
as	O
described	O
above	O
,	O
we	O
can	O
define	O
transitions	O
among	O
configurations	O
.	O

Any	O
sequence	O
of	O
transitions	O
starting	O
from	O
the	O
initial	O
configuration	O
is	O
called	O
a	O
computation	O
.	O

A	O
computation	O
halts	O
,	O
also	O
called	O
successful	O
,	O
if	O
it	O
reaches	O
a	O
configuration	O
where	O
no	O
rule	O
can	O
be	O
applied	O
in	O
any	O
neuron	O
in	O
the	O
system	O
.	O

For	O
each	O
successful	O
computation	O
of	O
the	O
system	O
,	O
a	O
computation	O
result	O
is	O
generated	O
,	O
which	O
is	O
total	O
the	O
number	O
of	O
spikes	O
sent	O
to	O
the	O
environment	O
by	O
the	O
output	O
neuron	O
.	O

System	O
Π	O
generates	O
a	O
number	O
n	O
as	O
follows	O
.	O

The	O
computation	O
of	O
the	O
system	O
starts	O
from	O
the	O
initial	O
configuration	O
and	O
finally	O
halts	O
,	O
emitting	O
totally	O
n	O
spikes	O
to	O
the	O
environment	O
.	O

The	O
set	O
of	O
all	O
numbers	O
computed	O
in	O
this	O
way	O
by	O
Π	O
is	O
denoted	O
by	O
Nall	O
(	O
Π	O
)	O
(	O
the	O
subscript	O
all	O
indicates	O
that	O
the	O
computation	O
result	O
is	O
the	O
total	O
number	O
of	O
spikes	O
emitted	O
into	O
the	O
environment	O
by	O
the	O
system	O
).	O

System	O
Π	O
can	O
also	O
work	O
in	O
the	O
accepting	O
mode	O
.	O

A	O
number	O
n	O
is	O
read	O
through	O
input	O
neurons	O
from	O
the	O
environment	O
in	O
form	O
of	O
spike	O
train	O
10n	O
−	O
11	O
,	O
which	O
will	O
be	O
stored	O
in	O
a	O
specified	O
neuron	O
σ1	O
in	O
the	O
form	O
of	O
f	O
(	O
n	O
)	O
spikes	O
.	O

If	O
the	O
computation	O
eventually	O
halts	O
,	O
then	O
number	O
n	O
is	O
said	O
to	O
be	O
accepted	O
by	O
Π	O
.	O

The	O
set	O
of	O
numbers	O
accepted	O
by	O
Π	O
is	O
denoted	O
by	O
Nacc	O
(	O
Π	O
).	O

It	O
is	O
denoted	O
by	O
NmSPSOall	O
(	O
creh	O
,	O
delg	O
,	O
ruler	O
)	O
(	O
resp	O
.	O
NmSPSOacc	O
(	O
creh	O
′,	O
delg	O
′,	O
ruler	O
′))	O
the	O
family	O
of	O
sets	O
of	O
numbers	O
computed	O
(	O
resp	O
.	O

accepted	O
)	O
by	O
SN	O
P	O
systems	O
with	O
self	O
-	O
organization	O
of	O
degree	O
m	O
,	O
where	O
h	O
(	O
resp	O
.	O
h	O
′)	O
indicates	O
the	O
maximal	O
number	O
of	O
synapses	O
that	O
can	O
be	O
created	O
with	O
using	O
a	O
synapse	O
creation	O
rule	O
,	O
g	O
(	O
resp	O
.	O
g	O
′)	O
is	O
the	O
maximal	O
number	O
of	O
synapses	O
that	O
can	O
be	O
deleted	O
with	O
using	O
a	O
synapse	O
deletion	O
rule	O
,	O
r	O
(	O
resp	O
.	O
r	O
′)	O
is	O
the	O
maximal	O
number	O
of	O
rules	O
in	O
each	O
neuron	O
,	O
and	O
the	O
subscript	O
all	O
indicates	O
the	O
computation	O
result	O
is	O
encoded	O
by	O
the	O
number	O
of	O
spikes	O
emitted	O
into	O
the	O
environment	O
(	O
resp	O
.	O
the	O
subscript	O
acc	O
indicates	O
the	O
system	O
works	O
in	O
a	O
accepting	O
mode	O
).	O

If	O
the	O
parameters	O
are	O
not	O
bounded	O
,	O
i	O
.	O
e	O
.,	O
there	O
is	O
no	O
limit	O
imposed	O
on	O
them	O
,	O
then	O
they	O
are	O
replaced	O
with	O
*.	O

In	O
order	O
to	O
compute	O
a	O
function	O
f	O
:	O
Nk	O
→	O
N	O
by	O
SN	O
P	O
systems	O
with	O
self	O
-	O
organization	O
,	O
k	O
natural	O
numbers	O
n1	O
,	O
n2	O
,	O
…,	O
nk	O
are	O
introduced	O
in	O
the	O
system	O
by	O
reading	O
from	O
the	O
environment	O
a	O
spike	O
train	O
(	O
which	O
is	O
a	O
binary	O
sequence	O
)	O
.	O

The	O
input	O
neuron	O
has	O
a	O
synapse	O
pointing	O
from	O
the	O
environment	O
,	O
by	O
which	O
the	O
spikes	O
can	O
enter	O
it	O
.	O

The	O
input	O
neuron	O
reads	O
a	O
spike	O
in	O
each	O
step	O
corresponding	O
to	O
a	O
digit	O
1	O
from	O
the	O
string	O
z	O
;	O
otherwise	O
,	O
no	O
spike	O
is	O
received	O
.	O

Note	O
that	O
exactly	O
k	O
+	O
1	O
spikes	O
are	O
introduced	O
into	O
the	O
system	O
through	O
the	O
input	O
neuron	O
,	O
i	O
.	O
e	O
.,	O
after	O
the	O
last	O
spike	O
,	O
it	O
is	O
assumed	O
that	O
no	O
further	O
spike	O
is	O
coming	O
to	O
the	O
input	O
neuron	O
.	O

The	O
output	O
neuron	O
has	O
a	O
synapse	O
pointing	O
to	O
the	O
environment	O
from	O
it	O
,	O
by	O
which	O
the	O
spikes	O
can	O
be	O
emitted	O
to	O
the	O
environment	O
.	O

The	O
result	O
of	O
the	O
computation	O
is	O
the	O
total	O
number	O
of	O
spikes	O
emitted	O
into	O
the	O
environment	O
by	O
the	O
output	O
neuron	O
,	O
hence	O
producing	O
r	O
spikes	O
with	O
r	O
=	O
f	O
(	O
n1	O
,	O
n2	O
,	O
…,	O
nk	O
).	O

SN	O
P	O
systems	O
with	O
self	O
-	O
organization	O
can	O
be	O
represented	O
graphically	O
,	O
which	O
is	O
easier	O
to	O
understand	O
than	O
that	O
in	O
a	O
symbolic	O
way	O
.	O

A	O
rounded	O
rectangle	O
with	O
the	O
initial	O
number	O
of	O
spikes	O
and	O
rules	O
is	O
used	O
to	O
represent	O
a	O
neuron	O
and	O
a	O
directed	O
edge	O
connecting	O
two	O
neurons	O
represents	O
a	O
synapse	O
.	O

In	O
the	O
following	O
proofs	O
,	O
the	O
notion	O
of	O
register	O
machine	O
is	O
used	O
.	O

A	O
register	O
machine	O
is	O
a	O
construct	O
M	O
=	O
(	O
m	O
,	O
H	O
,	O
l0	O
,	O
lh	O
,	O
I	O
),	O
where	O
m	O
is	O
the	O
number	O
of	O
registers	O
,	O
H	O
is	O
the	O
set	O
of	O
instruction	O
labels	O
,	O
l0	O
is	O
the	O
start	O
label	O
,	O
lh	O
is	O
the	O
halt	O
label	O
(	O
assigned	O
to	O
instruction	O
HALT	O
),	O
and	O
I	O
is	O
the	O
set	O
of	O
instructions	O
;	O
each	O
label	O
from	O
H	O
labels	O
only	O
one	O
instruction	O
from	O
I	O
,	O
thus	O
precisele	O
following	O
forms	O
:	O
li	O
:	O
(	O
ADD	O
(	O
r	O
),	O
lj	O
,	O
lk	O
)	O
(	O
add	O
1	O
to	O
register	O
r	O
and	O
then	O
go	O
to	O
one	O
of	O
the	O
instructions	O
with	O
labels	O
lj	O
,	O
lk	O
),	O
li	O
:	O
(	O
SUB	O
(	O
r	O
),	O
lj	O
,	O
lk	O
)	O
(	O
if	O
register	O
r	O
is	O
non	O
-	O
zero	O
,	O
then	O
subtract	O
1	O
from	O
it	O
,	O
and	O
go	O
to	O
the	O
instruction	O
with	O
label	O
lj	O
;	O
otherwise	O
,	O
go	O
to	O
the	O
instruction	O
with	O
label	O
lk	O
),	O
lh	O
:	O
HALT	O
(	O
the	O
halt	O
instruction	O
).	O

As	O
number	O
generator	O

A	O
register	O
machine	O
M	O
computes	O
a	O
number	O
n	O
as	O
follows	O
.	O

It	O
starts	O
by	O
using	O
initial	O
instruction	O
l0	O
with	O
all	O
registers	O
storing	O
number	O
0	O
.	O

When	O
it	O
reaches	O
halt	O
instruction	O
lh	O
,	O
the	O
number	O
stored	O
in	O
register	O
1	O
is	O
called	O
the	O
number	O
generated	O
or	O
computed	O
by	O
register	O
machine	O
M	O
.	O

The	O
set	O
of	O
numbers	O
generated	O
or	O
computed	O
by	O
register	O
machine	O
M	O
is	O
denoted	O
by	O
N	O
(	O
M	O
).	O

It	O
is	O
known	O
that	O
register	O
machines	O
compute	O
all	O
sets	O
of	O
numbers	O
which	O
are	O
Turing	O
computable	O
,	O
hence	O
they	O
characterize	O
NRE	O
,	O
i	O
.	O
e	O
.,	O
N	O
(	O
M	O
)	O
=	O
NRE	O
,	O
where	O
NRE	O
is	O
the	O
family	O
of	O
Turing	O
computable	O
sets	O
of	O
numbers44	O
.	O

Without	O
loss	O
of	O
generality	O
,	O
it	O
can	O
be	O
assumed	O
that	O
in	O
the	O
halting	O
configuration	O
,	O
all	O
registers	O
different	O
from	O
the	O
first	O
one	O
are	O
empty	O
,	O
and	O
that	O
the	O
first	O
register	O
is	O
never	O
decremented	O
during	O
the	O
computation	O
(	O
i	O
.	O
e	O
.,	O
its	O
content	O
is	O
only	O
added	O
to	O
).	O

When	O
the	O
power	O
of	O
two	O
number	O
generating	O
devices	O
D1	O
and	O
D2	O
are	O
compared	O
,	O
number	O
zero	O
is	O
ignored	O
;	O
that	O
is	O
,	O
N	O
(	O
D1	O
)	O
=	O
N	O
(	O
D2	O
)	O
if	O
and	O
only	O
if	O
N	O
(	O
D1	O
)	O
−	O
{	O
0	O
}	O
=	O
N	O
(	O
D2	O
)	O
−	O
{	O
0	O
}	O
(	O
this	O
corresponds	O
to	O
the	O
usual	O
practice	O
of	O
ignoring	O
the	O
empty	O
string	O
in	O
language	O
and	O
automata	O
theory	O
).	O

Theorem	O
4	O
.	O
N	O
*	O
SPSOall	O
(	O
cre	O
*,	O
del	O
*,	O
rule5	O
)	O
=	O
NRE	O
.	O

Proof	O

It	O
only	O
has	O
to	O
prove	O
NRE	O
⊆	O
N	O
*	O
SPSOall	O
(	O
cre	O
*,	O
del	O
*,	O
rule5	O
),	O
since	O
the	O
converse	O
inclusion	O
is	O
straightforward	O
from	O
the	O
Turing	O
-	O
Church	O
thesis	O
(	O
or	O
it	O
can	O
be	O
proved	O
by	O
the	O
similar	O
technical	O
details	O
in	O
Section	O
8	O
.	O
1	O
in	O
ref	O
.	O
46	O
,	O
but	O
is	O
cumbersome	O
).	O

To	O
achieve	O
this	O
,	O
we	O
use	O
the	O
characterization	O
of	O
NRE	O
by	O
means	O
of	O
register	O
machines	O
in	O
the	O
generative	O
mode	O
.	O

Let	O
us	O
consider	O
a	O
register	O
machine	O
M	O
=	O
(	O
m	O
,	O
H	O
,	O
l0	O
,	O
lh	O
,	O
I	O
)	O
defined	O
above	O
.	O

It	O
is	O
assumed	O
that	O
register	O
1	O
of	O
M	O
is	O
the	O
output	O
register	O
,	O
which	O
is	O
never	O
decremented	O
during	O
the	O
computation	O
.	O

For	O
each	O
register	O
r	O
of	O
M	O
,	O
let	O
sr	O
be	O
the	O
number	O
of	O
instructions	O
of	O
the	O
form	O
li	O
:	O
(	O
SUB	O
(	O
r	O
),	O
lj	O
,	O
lk	O
),	O
i	O
.	O
e	O
.,	O
the	O
number	O
of	O
SUB	O
instructions	O
acting	O
on	O
register	O
r	O
.	O

If	O
there	O
is	O
no	O
such	O
SUB	O
instruction	O
,	O
then	O
sr	O
=	O
0	O
,	O
which	O
is	O
the	O
case	O
for	O
the	O
first	O
register	O
r	O
=	O
1	O
.	O

In	O
what	O
follows	O
,	O
a	O
specific	O
SN	O
P	O
system	O
with	O
self	O
-	O
organization	O
Π	O
is	O
constructed	O
to	O
simulate	O
register	O
machine	O
M	O
.	O

System	O
Π	O
consists	O
of	O
three	O
modules	O
–	O
ADD	O
,	O
SUB	O
and	O
FIN	O
modules	O
.	O

The	O
ADD	O
and	O
SUB	O
modules	O
are	O
used	O
to	O
simulate	O
the	O
operations	O
of	O
ADD	O
and	O
SUB	O
instructions	O
of	O
M	O
;	O
and	O
the	O
FIN	O
module	O
is	O
used	O
to	O
output	O
a	O
computation	O
result	O
.	O

In	O
general	O
,	O
with	O
any	O
register	O
r	O
of	O
M	O
,	O
a	O
neuron	O
σr	O
in	O
system	O
Π	O
is	O
associated	O
;	O
the	O
number	O
stored	O
in	O
register	O
r	O
is	O
encoded	O
by	O
the	O
number	O
of	O
spikes	O
in	O
neuron	O
σr	O
.	O

Specifically	O
,	O
if	O
register	O
r	O
stores	O
number	O
n	O
≥	O
0	O
,	O
then	O
there	O
are	O
5n	O
spikes	O
in	O
neuron	O
σr	O
.	O

For	O
each	O
label	O
li	O
of	O
an	O
instruction	O
in	O
M	O
,	O
a	O
neuron	O
is	O
associated	O
.	O

During	O
the	O
simulation	O
,	O
when	O
neuron	O
receives	O
6	O
spikes	O
,	O
it	O
becomes	O
active	O
and	O
starts	O
to	O
simulate	O
instruction	O
li	O
:	O
(	O
OP	O
(	O
r	O
),	O
lj	O
,	O
lk	O
)	O
of	O
M	O
:	O
the	O
process	O
starts	O
with	O
neuron	O
activated	O
,	O
operates	O
on	O
the	O
number	O
of	O
spikes	O
in	O
neuron	O
σr	O
as	O
requested	O
by	O
OP	O
,	O
then	O
sends	O
6	O
spikes	O
into	O
neuron	O
or	O
,	O
which	O
becomes	O
active	O
in	O
this	O
way	O
.	O

Since	O
there	O
is	O
no	O
initial	O
synapse	O
in	O
system	O
Π	O
,	O
some	O
synapses	O
are	O
created	O
to	O
pass	O
spikes	O
to	O
target	O
neurons	O
with	O
synapse	O
creation	O
rules	O
,	O
after	O
that	O
the	O
created	O
synapses	O
will	O
be	O
deleted	O
when	O
simulation	O
completes	O
by	O
synapse	O
deletion	O
rules	O
.	O

When	O
neuron	O
(	O
associated	O
with	O
the	O
halting	O
instruction	O
lh	O
of	O
M	O
)	O
is	O
activated	O
,	O
a	O
computation	O
in	O
M	O
is	O
completely	O
simulated	O
by	O
system	O
Π	O
.	O

The	O
following	O
describes	O
the	O
works	O
of	O
ADD	O
,	O
SUB	O
,	O
and	O
FIN	O
modules	O
of	O
the	O
SN	O
P	O
systems	O
with	O
self	O
-	O
organization	O
.	O

Module	O
ADD	O
(	O
shown	O
in	O
Fig	O
.	O
1	O
):	O
Simulating	O
the	O
ADD	O
instruction	O
li	O
:	O
(	O
ADD	O
(	O
r	O
),	O
lj	O
,	O
lk	O
).	O

Initially	O
,	O
there	O
is	O
no	O
synapse	O
in	O
system	O
Π	O
,	O
and	O
all	O
the	O
neurons	O
have	O
no	O
spike	O
with	O
exception	O
that	O
neuron	O
has	O
6	O
spikes	O
.	O

This	O
means	O
system	O
Π	O
starts	O
by	O
simulating	O
initial	O
instruction	O
l0	O
.	O

Let	O
us	O
assume	O
that	O
at	O
step	O
t	O
,	O
an	O
instruction	O
li	O
:	O
(	O
ADD	O
(	O
r	O
),	O
lj	O
,	O
lk	O
)	O
has	O
to	O
be	O
simulated	O
,	O
with	O
6	O
spikes	O
present	O
in	O
neuron	O
(	O
like	O
in	O
the	O
initial	O
configuration	O
)	O
and	O
no	O
spike	O
in	O
any	O
other	O
neurons	O
,	O
except	O
in	O
those	O
neurons	O
associated	O
with	O
registers	O
.	O

At	O
step	O
t	O
,	O
neuron	O
has	O
6	O
spikes	O
,	O
and	O
synapse	O
creation	O
rule	O
is	O
applied	O
in	O
,	O
it	O
generates	O
three	O
synapses	O
connecting	O
neuron	O
to	O
neurons	O
,	O
and	O
σr	O
.	O

Meanwhile	O
,	O
it	O
consumes	O
5	O
spikes	O
(	O
one	O
spike	O
remaining	O
)	O
and	O
sends	O
5	O
spikes	O
to	O
each	O
of	O
neurons	O
,	O
and	O
σr	O
.	O

The	O
number	O
of	O
spikes	O
in	O
neuron	O
σr	O
is	O
increased	O
by	O
5	O
,	O
which	O
simulates	O
adding	O
1	O
to	O
register	O
r	O
of	O
M	O
.	O

At	O
step	O
t	O
+	O
1	O
,	O
neuron	O
deletes	O
the	O
three	O
synapses	O
created	O
at	O
step	O
t	O
by	O
using	O
rule	O
.	O

At	O
the	O
same	O
moment	O
,	O
neuron	O
uses	O
synapse	O
creation	O
rule	O
a5	O
/	O
a4	O
→	O
+	O
(	O
a3	O
,	O
{	O
lj	O
,	O
lk	O
}),	O
and	O
creates	O
two	O
synapses	O
to	O
neurons	O
and	O
,	O
as	O
well	O
as	O
sends	O
3	O
spikes	O
to	O
each	O
of	O
the	O
two	O
neurons	O
.	O

At	O
step	O
t	O
+	O
2	O
,	O
neuron	O
deletes	O
the	O
two	O
synapses	O
by	O
using	O
synapse	O
deletion	O
rule	O
a	O
→	O
−	O
(	O
λ	O
,	O
{	O
lj	O
,	O
lk	O
}).	O

In	O
neuron	O
,	O
there	O
are	O
5	O
spikes	O
at	O
step	O
t	O
+	O
1	O
such	O
that	O
both	O
of	O
synapse	O
creation	O
rules	O
a5	O
/	O
a4	O
→	O
+	O
(	O
a3	O
,	O
{	O
lj	O
})	O
and	O
a5	O
/	O
a4	O
→	O
+	O
(	O
a3	O
,	O
{	O
lk	O
})	O
are	O
enabled	O
,	O
but	O
only	O
one	O
of	O
them	O
is	O
non	O
-	O
deterministically	O
used	O
.	O

–	O
If	O
rule	O
a5	O
/	O
a4	O
→	O
+	O
(	O
a3	O
,	O
{	O
lj	O
})	O
is	O
chosen	O
to	O
use	O
,	O
neuron	O
creates	O
a	O
synapse	O
and	O
sends	O
3	O
spikes	O
to	O
neuron	O
.	O

In	O
this	O
case	O
,	O
neuron	O
accumulates	O
6	O
spikes	O
,	O
which	O
means	O
system	O
Π	O
starts	O
to	O
simulate	O
instruction	O
lj	O
of	O
M	O
.	O

One	O
step	O
later	O
,	O
with	O
one	O
spike	O
inside	O
neuron	O
uses	O
rule	O
a	O
→	O
−	O
(	O
λ	O
,	O
{	O
lj	O
,	O
lk	O
})	O
to	O
delete	O
the	O
synapse	O
to	O
neuron	O
,	O
and	O
neuron	O
removes	O
the	O
3	O
spikes	O
(	O
from	O
neuron	O
)	O
by	O
the	O
forgetting	O
rule	O
a3	O
→	O
λ	O
.	O

–	O
If	O
rule	O
a5	O
/	O
a4	O
→	O
+	O
(	O
a3	O
,	O
{	O
lk	O
})	O
is	O
selected	O
to	O
apply	O
,	O
neuron	O
creates	O
a	O
synapse	O
and	O
sends	O
3	O
spikes	O
to	O
neuron	O
.	O

Neuron	O
accumulates	O
6	O
spikes	O
,	O
which	O
indicates	O
system	O
Π	O
goes	O
to	O
simulate	O
instruction	O
lk	O
of	O
M	O
.	O

One	O
step	O
later	O
,	O
neuron	O
removes	O
the	O
3	O
spikes	O
by	O
using	O
forgetting	O
rule	O
a3	O
→	O
λ	O
,	O
and	O
the	O
synapse	O
from	O
neuron	O
to	O
is	O
deleted	O
by	O
using	O
rule	O
a	O
→	O
−	O
(	O
λ	O
,	O
{	O
lj	O
,	O
lk	O
})	O
in	O
neuron	O
.	O

Therefore	O
,	O
from	O
firing	O
neuron	O
,	O
system	O
Π	O
adds	O
5	O
spikes	O
to	O
neuron	O
σr	O
and	O
non	O
-	O
deterministically	O
activates	O
one	O
of	O
the	O
neurons	O
and	O
,	O
which	O
correctly	O
simulates	O
the	O
ADD	O
instruction	O
li	O
:	O
(	O
ADD	O
(	O
r	O
),	O
lj	O
,	O
lk	O
).	O

When	O
the	O
simulation	O
of	O
ADD	O
instruction	O
is	O
completed	O
,	O
the	O
ADD	O
module	O
returns	O
to	O
its	O
initial	O
topological	O
structure	O
,	O
i	O
.	O
e	O
.,	O
there	O
is	O
no	O
synapse	O
in	O
the	O
module	O
.	O

The	O
dynamic	O
transformation	O
of	O
topological	O
structure	O
and	O
the	O
numbers	O
of	O
spikes	O
in	O
neurons	O
of	O
ADD	O
module	O
during	O
the	O
ADD	O
instruction	O
simulation	O
with	O
neuron	O
or	O
finally	O
activated	O
is	O
shown	O
in	O
Figs	O
2	O
and	O
3	O
.	O

In	O
the	O
figures	O
,	O
the	O
spiking	O
rules	O
are	O
omitted	O
for	O
clear	O
illustration	O
,	O
neurons	O
are	O
represented	O
by	O
circles	O
with	O
the	O
number	O
of	O
spikes	O
and	O
directed	O
edges	O
is	O
used	O
to	O
represent	O
the	O
synapses	O
.	O

Module	O
SUB	O
(	O
shown	O
in	O
Fig	O
.	O
4	O
):	O
Simulating	O
the	O
SUB	O
instruction	O
li	O
:	O
(	O
SUB	O
(	O
r	O
),	O
lj	O
,	O
lk	O
).	O

Given	O
starting	O
time	O
stamp	O
t	O
,	O
system	O
Π	O
simulates	O
a	O
SUB	O
instruction	O
li	O
:	O
(	O
SUB	O
(	O
r	O
),	O
lj	O
,	O
lk	O
).	O

Let	O
sr	O
be	O
the	O
number	O
of	O
SUB	O
instructions	O
acting	O
on	O
register	O
r	O
and	O
the	O
set	O
of	O
labels	O
of	O
instructions	O
acting	O
on	O
register	O
r	O
be	O
.	O

Obviously	O
,	O
it	O
holds	O
.	O

At	O
step	O
t	O
,	O
neuron	O
has	O
6	O
spikes	O
,	O
and	O
becomes	O
active	O
by	O
using	O
synapse	O
creation	O
rule	O
,	O
creating	O
synapses	O
and	O
sending	O
4	O
spikes	O
to	O
each	O
of	O
neurons	O
,	O
and	O
σr	O
.	O

With	O
4	O
spikes	O
inside	O
,	O
neurons	O
and	O
keep	O
inactive	O
at	O
step	O
t	O
+	O
1	O
because	O
no	O
rule	O
can	O
be	O
used	O
.	O

In	O
neuron	O
σr	O
,	O
it	O
has	O
the	O
following	O
two	O
cases	O
.	O

–	O
If	O
neuron	O
σr	O
has	O
5n	O
(	O
n	O
>	O
0	O
)	O
spikes	O
(	O
corresponding	O
to	O
the	O
fact	O
that	O
the	O
number	O
stored	O
in	O
register	O
r	O
is	O
n	O
,	O
and	O
n	O
>	O
0	O
),	O
then	O
by	O
receiving	O
4	O
spikes	O
from	O
neuron	O
,	O
it	O
accumulates	O
5n	O
+	O
4	O
spikes	O
and	O
becomes	O
active	O
by	O
using	O
rule	O
at	O
step	O
t	O
+	O
1	O
.	O

It	O
creates	O
a	O
synapse	O
to	O
each	O
of	O
neurons	O
and	O
with	O
and	O
sending	O
6	O
spikes	O
to	O
the	O
neurons	O
.	O

By	O
consuming	O
8	O
spikes	O
,	O
the	O
number	O
of	O
spikes	O
in	O
neuron	O
σr	O
becomes	O
5n	O
+	O
4	O
−	O
8	O
=	O
5	O
(	O
n	O
−	O
1	O
)	O
+	O
1	O
(	O
n	O
≥	O
0	O
)	O
such	O
that	O
rule	O
is	O
enabled	O
and	O
applied	O
at	O
step	O
t	O
+	O
2	O
.	O

With	O
application	O
of	O
the	O
rule	O
,	O
neuron	O
σr	O
removes	O
the	O
synapses	O
from	O
neuron	O
σr	O
to	O
neurons	O
and	O
,	O
.	O

Meanwhile	O
,	O
neurons	O
and	O
with	O
s	O
≠	O
i	O
remove	O
the	O
6	O
spikes	O
by	O
using	O
forgetting	O
rule	O
a6	O
→	O
λ	O
,	O
and	O
neuron	O
removes	O
the	O
10	O
spikes	O
by	O
forgetting	O
rule	O
a10	O
→	O
λ	O
.	O

Neuron	O
accumulates	O
10	O
spikes	O
(	O
4	O
spikes	O
from	O
neuron	O
and	O
6	O
spikes	O
from	O
neuron	O
σr	O
),	O
and	O
rule	O
a10	O
/	O
a9	O
→	O
+	O
(	O
a6	O
,	O
{	O
lj	O
})	O
is	O
applied	O
at	O
step	O
t	O
+	O
2	O
,	O
creating	O
a	O
synapse	O
and	O
sending	O
6	O
spikes	O
to	O
neuron	O
.	O

In	O
this	O
case	O
,	O
neuron	O
receives	O
6	O
spikes	O
,	O
which	O
means	O
system	O
Π	O
starts	O
to	O
simulate	O
instruction	O
lj	O
of	O
M	O
.	O

One	O
step	O
later	O
,	O
the	O
synapse	O
from	O
neuron	O
to	O
neuron	O
is	O
deleted	O
by	O
using	O
synapse	O
deletion	O
rule	O
a	O
→	O
−	O
(	O
λ	O
,	O
{	O
lj	O
}).	O

–	O
If	O
neuron	O
σr	O
has	O
no	O
spike	O
(	O
corresponding	O
to	O
the	O
fact	O
that	O
the	O
number	O
stored	O
in	O
register	O
r	O
is	O
0	O
),	O
then	O
after	O
receiving	O
4	O
spikes	O
from	O
neuron	O
,	O
it	O
has	O
4	O
spikes	O
and	O
rule	O
is	O
used	O
,	O
creating	O
a	O
synapse	O
to	O
each	O
of	O
neurons	O
and	O
with	O
and	O
sending	O
3	O
spikes	O
to	O
the	O
neurons	O
.	O

Neuron	O
σr	O
remains	O
one	O
spike	O
,	O
and	O
synapse	O
deletion	O
rule	O
is	O
applied	O
at	O
step	O
t	O
+	O
2	O
,	O
removing	O
the	O
synapses	O
from	O
neuron	O
σr	O
to	O
neurons	O
and	O
,	O
.	O

At	O
the	O
same	O
moment	O
,	O
neurons	O
and	O
with	O
s	O
≠	O
i	O
remove	O
the	O
3	O
spikes	O
by	O
using	O
forgetting	O
rule	O
a3	O
→	O
λ	O
,	O
and	O
neuron	O
removes	O
7	O
spikes	O
using	O
spiking	O
rule	O
a7	O
→	O
λ	O
.	O

Having	O
7	O
spikes	O
,	O
Neuron	O
becomes	O
active	O
by	O
using	O
rule	O
a7	O
/	O
a6	O
→	O
+	O
(	O
a6	O
,	O
{	O
lk	O
})	O
at	O
step	O
t	O
+	O
2	O
,	O
creating	O
a	O
synapse	O
to	O
neuron	O
and	O
sending	O
6	O
spikes	O
to	O
neuron	O
.	O

In	O
this	O
case	O
,	O
neuron	O
receives	O
6	O
spikes	O
,	O
which	O
means	O
system	O
Π	O
starts	O
to	O
simulate	O
instruction	O
lk	O
of	O
M	O
.	O

At	O
step	O
t	O
+	O
3	O
,	O
neuron	O
uses	O
rule	O
a	O
→	O
−	O
(	O
λ	O
,	O
{	O
lk	O
})	O
to	O
remove	O
the	O
synapse	O
to	O
neuron	O
.	O

The	O
simulation	O
of	O
SUB	O
instruction	O
performs	O
correctly	O
:	O
System	O
Π	O
starts	O
from	O
having	O
6	O
spikes	O
and	O
becoming	O
active	O
,	O
and	O
ends	O
in	O
neuron	O
receiving	O
6	O
spikes	O
(	O
if	O
the	O
number	O
stored	O
in	O
register	O
r	O
is	O
great	O
than	O
0	O
and	O
decreased	O
by	O
one	O
),	O
or	O
in	O
neuron	O
receiving	O
6	O
spikes	O
(	O
if	O
the	O
number	O
stored	O
in	O
register	O
r	O
is	O
0	O
).	O

When	O
the	O
simulation	O
of	O
SUB	O
instruction	O
is	O
completed	O
,	O
the	O
SUB	O
module	O
returns	O
to	O
its	O
initial	O
topological	O
structure	O
,	O
i	O
.	O
e	O
.,	O
there	O
is	O
no	O
synapse	O
in	O
the	O
module	O
.	O

The	O
dynamic	O
transformation	O
of	O
topological	O
structure	O
and	O
the	O
numbers	O
of	O
spikes	O
in	O
involved	O
neurons	O
in	O
the	O
SUB	O
instruction	O
simulation	O
with	O
neuron	O
(	O
resp	O
.	O
neuron	O
)	O
finally	O
activated	O
is	O
shown	O
in	O
Fig	O
.	O
5	O
(	O
resp	O
.	O
Fig	O
.	O
6	O
).	O

Module	O
FIN	O
(	O
shown	O
in	O
Fig	O
.	O
7	O
)	O
–	O
outputting	O
the	O
result	O
of	O
computation	O
.	O

Assume	O
that	O
at	O
step	O
t	O
the	O
computation	O
in	O
M	O
halts	O
,	O
i	O
.	O
e	O
.,	O
the	O
halting	O
instruction	O
is	O
reached	O
.	O

In	O
this	O
case	O
,	O
neuron	O
in	O
Π	O
receives	O
6	O
spikes	O
.	O

At	O
that	O
moment	O
,	O
neuron	O
σ1	O
contains	O
5n	O
spikes	O
,	O
for	O
the	O
number	O
n	O
≥	O
1	O
stored	O
in	O
register	O
1	O
of	O
M	O
.	O

With	O
6	O
spikes	O
inside	O
,	O
neuron	O
becomes	O
active	O
by	O
using	O
rule	O
a6	O
/	O
a5	O
→	O
+(	O
a2	O
,	O
{	O
1	O
}),	O
creating	O
a	O
synapse	O
to	O
neuron	O
σ1	O
and	O
sending	O
2	O
spikes	O
to	O
neuron	O
σ1	O
.	O

Neuron	O
ends	O
with	O
one	O
spike	O
,	O
and	O
rule	O
a	O
→	O
−(	O
λ	O
,	O
{	O
1	O
})	O
is	O
used	O
,	O
removing	O
the	O
synapse	O
to	O
neuron	O
σ1	O
one	O
step	O
later	O
.	O

After	O
neuron	O
σ1	O
receives	O
the	O
2	O
spikes	O
from	O
neuron	O
,	O
the	O
number	O
of	O
spikes	O
in	O
neuron	O
σ1	O
becomes	O
5n	O
+	O
2	O
and	O
rule	O
a2	O
(	O
a5	O
)+/	O
a	O
→	O
+(	O
λ	O
,	O
{	O
0	O
})	O
is	O
enabled	O
and	O
applied	O
at	O
step	O
t	O
+	O
2	O
.	O

By	O
using	O
the	O
rule	O
,	O
neuron	O
σ1	O
consumes	O
one	O
spike	O
and	O
creates	O
a	O
synapse	O
to	O
the	O
environment	O
.	O

Neuron	O
σ1	O
contains	O
5n	O
+	O
1	O
spikes	O
such	O
that	O
spiking	O
rule	O
a	O
(	O
a5	O
)+/	O
a5	O
→	O
a	O
is	O
used	O
,	O
consuming	O
5	O
spikes	O
and	O
emitting	O
one	O
spike	O
to	O
the	O
environment	O
at	O
step	O
t	O
+	O
3	O
.	O

Note	O
that	O
the	O
number	O
of	O
spikes	O
in	O
neuron	O
σ1	O
becomes	O
5	O
(	O
n	O
−	O
1	O
)	O
+	O
1	O
.	O

So	O
,	O
if	O
the	O
number	O
of	O
spikes	O
in	O
neuron	O
σ1	O
is	O
not	O
one	O
,	O
then	O
neuron	O
σ1	O
will	O
fire	O
again	O
in	O
the	O
next	O
step	O
sending	O
one	O
spike	O
into	O
the	O
environment	O
.	O

In	O
this	O
way	O
,	O
neuron	O
σ1	O
can	O
fire	O
for	O
n	O
times	O
,	O
i	O
.	O
e	O
.,	O
until	O
the	O
number	O
of	O
spikes	O
in	O
neuron	O
σ1	O
reaches	O
one	O
.	O

For	O
each	O
time	O
when	O
neuron	O
σ1	O
fires	O
,	O
it	O
sends	O
one	O
spike	O
into	O
the	O
environment	O
.	O

So	O
,	O
in	O
total	O
,	O
neuron	O
σ1	O
sends	O
n	O
spikes	O
into	O
the	O
environment	O
,	O
which	O
is	O
exactly	O
the	O
number	O
stored	O
in	O
register	O
1	O
of	O
M	O
at	O
the	O
moment	O
when	O
the	O
computation	O
of	O
M	O
halts	O
.	O

When	O
neuron	O
σ1	O
has	O
one	O
spike	O
,	O
rule	O
a	O
→	O
−(	O
λ	O
,	O
{	O
0	O
})	O
is	O
used	O
to	O
remove	O
the	O
synapse	O
from	O
neuron	O
σ1	O
to	O
the	O
environment	O
,	O
and	O
system	O
Π	O
eventually	O
halts	O
.	O

The	O
dynamic	O
transformation	O
of	O
topological	O
structure	O
of	O
the	O
FIN	O
module	O
and	O
the	O
numbers	O
of	O
spikes	O
in	O
the	O
neurons	O
of	O
FIN	O
module	O
and	O
in	O
the	O
environment	O
are	O
shown	O
in	O
Fig	O
.	O
8	O
.	O

Based	O
on	O
the	O
description	O
of	O
the	O
work	O
of	O
system	O
Π	O
above	O
,	O
the	O
register	O
machine	O
M	O
is	O
correctly	O
simulated	O
by	O
system	O
Π	O
,	O
i	O
.	O
e	O
.,	O
N	O
(	O
M	O
)	O
=	O
Nall	O
(	O
Π	O
).	O

We	O
can	O
check	O
that	O
each	O
neuron	O
in	O
system	O
Π	O
has	O
at	O
most	O
three	O
rules	O
,	O
and	O
no	O
limit	O
is	O
imposed	O
on	O
the	O
numbers	O
of	O
neurons	O
and	O
the	O
synapses	O
that	O
can	O
be	O
created	O
(	O
or	O
deleted	O
)	O
by	O
using	O
one	O
synapse	O
creation	O
(	O
or	O
deletion	O
)	O
rule	O
.	O

Therefore	O
,	O
it	O
concludes	O
N	O
*	O
SPSOall	O
(	O
cre	O
*,	O
del	O
*,	O
rule5	O
)	O
=	O
NRE	O
.	O

This	O
concludes	O
the	O
proof	O
.	O

As	O
number	O
acceptor	O

Register	O
machine	O
can	O
work	O
in	O
the	O
accepting	O
mode	O
.	O

Number	O
n	O
is	O
accepted	O
by	O
register	O
machine	O
M	O
′	O
as	O
follows	O
.	O

Initially	O
,	O
number	O
n	O
is	O
stored	O
in	O
the	O
first	O
register	O
of	O
M	O
′	O
and	O
all	O
the	O
other	O
registers	O
are	O
empty	O
.	O

If	O
the	O
computation	O
starting	O
in	O
this	O
configuration	O
eventually	O
halts	O
,	O
then	O
the	O
number	O
n	O
is	O
said	O
to	O
be	O
accepted	O
by	O
register	O
machine	O
M	O
′.	O

The	O
set	O
of	O
numbers	O
accepted	O
by	O
register	O
machine	O
M	O
′	O
is	O
denoted	O
by	O
Nacc	O
(	O
M	O
′).	O

It	O
is	O
known	O
that	O
all	O
the	O
sets	O
of	O
numbers	O
in	O
NRE	O
can	O
be	O
accepted	O
by	O
register	O
machine	O
M	O
′,	O
even	O
using	O
the	O
deterministic	O
register	O
machine	O
;	O
i	O
.	O
e	O
.	O
the	O
machine	O
with	O
the	O
ADD	O
instructions	O
of	O
the	O
form	O
li	O
:	O
(	O
ADD	O
(	O
r	O
),	O
lj	O
,	O
lk	O
)	O
where	O
lj	O
=	O
lk	O
(	O
in	O
this	O
case	O
,	O
the	O
instruction	O
is	O
written	O
in	O
the	O
form	O
li	O
:	O
(	O
ADD	O
(	O
r	O
),	O
lj	O
))	O
44	O
.	O

Theorem	O
5	O
.	O
N	O
*	O
SPSOacc	O
(	O
cre	O
*,	O
del	O
*,	O
rule5	O
)	O
=	O
NRE	O
.	O

Proof	O

It	O
only	O
has	O
to	O
prove	O
NRE	O
⊆	O
N	O
*	O
SPSOacc	O
(	O
cre	O
*,	O
del	O
*,	O
rule5	O
),	O
since	O
the	O
converse	O
inclusion	O
is	O
straightforward	O
from	O
the	O
Turing	O
-	O
Church	O
thesis	O
.	O

In	O
what	O
follows	O
,	O
an	O
SN	O
P	O
system	O
Π	O
′	O
with	O
self	O
-	O
organization	O
working	O
in	O
accepting	O
mode	O
is	O
constructed	O
to	O
simulate	O
a	O
deterministic	O
register	O
machine	O
M	O
′	O
=	O
(	O
m	O
,	O
H	O
,	O
l0	O
,	O
lh	O
,	O
I	O
)	O
working	O
in	O
the	O
acceptive	O
mode	O
.	O

Actually	O
,	O
the	O
proof	O
is	O
given	O
by	O
modifying	O
the	O
proof	O
of	O
Theorem	O
4	O
.	O

Each	O
register	O
r	O
of	O
M	O
′	O
is	O
associated	O
with	O
a	O
neuron	O
σr	O
in	O
system	O
Π	O
′,	O
and	O
for	O
each	O
instruction	O
li	O
of	O
M	O
′	O
a	O
neuron	O
is	O
associated	O
.	O

A	O
number	O
n	O
stored	O
in	O
register	O
r	O
is	O
represented	O
by	O
5n	O
spikes	O
in	O
neuron	O
σr	O
.	O

The	O
system	O
Π	O
′	O
consists	O
of	O
an	O
INPUT	O
module	O
,	O
deterministic	O
ADD	O
and	O
SUB	O
modules	O
.	O

The	O
INPUT	O
module	O
is	O
shown	O
in	O
Fig	O
.	O
9	O
,	O
where	O
all	O
neurons	O
are	O
initially	O
empty	O
with	O
the	O
exception	O
that	O
input	O
neuron	O
σin	O
has	O
8	O
spikes	O
.	O

Spike	O
train	O
10n	O
−	O
11	O
is	O
introduced	O
into	O
the	O
system	O
through	O
input	O
neuron	O
σin	O
,	O
where	O
the	O
internal	O
between	O
the	O
two	O
spikes	O
in	O
the	O
spike	O
train	O
is	O
(	O
n	O
+	O
1	O
)	O
−	O
1	O
=	O
n	O
,	O
which	O
indicates	O
that	O
number	O
n	O
is	O
going	O
to	O
be	O
accepted	O
by	O
system	O
Π	O
′.	O

Assuming	O
at	O
step	O
t	O
neuron	O
σin	O
receives	O
the	O
first	O
spike	O
.	O

At	O
step	O
t	O
+	O
1	O
,	O
neuron	O
σin	O
contains	O
9	O
spikes	O
,	O
and	O
rule	O
a9	O
/	O
a6	O
→	O
+(	O
a6	O
,	O
{	O
I1	O
,	O
I2	O
})	O
is	O
used	O
,	O
creating	O
a	O
synapse	O
from	O
neuron	O
σin	O
to	O
neurons	O
and	O
.	O

Meanwhile	O
,	O
neuron	O
σin	O
sends	O
6	O
spikes	O
to	O
the	O
two	O
neurons	O
.	O

In	O
neuron	O
σin	O
,	O
6	O
spikes	O
are	O
consumed	O
and	O
3	O
spikes	O
remain	O
.	O

With	O
6	O
spikes	O
inside	O
,	O
neurons	O
and	O
become	O
active	O
at	O
step	O
t	O
+	O
2	O
.	O

Neuron	O
uses	O
rule	O
a6	O
/	O
a	O
→	O
+(	O
λ	O
,	O
{	O
I2	O
})	O
to	O
create	O
a	O
synapse	O
to	O
neuron	O
;	O
and	O
neuron	O
uses	O
rule	O
a6	O
/	O
a	O
→	O
+(	O
λ	O
,	O
{	O
I1	O
,	O
1	O
})	O
to	O
create	O
a	O
synapse	O
to	O
each	O
of	O
neurons	O
and	O
σ1	O
.	O

Each	O
of	O
neurons	O
and	O
has	O
5	O
spikes	O
left	O
.	O

From	O
step	O
t	O
+	O
3	O
on	O
,	O
neurons	O
and	O
fire	O
and	O
begin	O
to	O
exchange	O
5	O
spikes	O
between	O
them	O
.	O

In	O
this	O
way	O
,	O
neuron	O
σ1	O
receives	O
5	O
spikes	O
from	O
neurons	O
at	O
each	O
step	O
.	O

At	O
step	O
t	O
+	O
n	O
,	O
neuron	O
σin	O
receives	O
the	O
second	O
spike	O
from	O
the	O
environment	O
,	O
accumulating	O
4	O
spikes	O
inside	O
.	O

At	O
step	O
t	O
+	O
n	O
+	O
1	O
,	O
neuron	O
σin	O
fires	O
for	O
the	O
second	O
time	O
by	O
using	O
spiking	O
rule	O
a4	O
/	O
a3	O
→	O
a3	O
,	O
sending	O
3	O
spikes	O
to	O
neurons	O
and	O
.	O

Each	O
of	O
neurons	O
and	O
accumulates	O
8	O
spikes	O
.	O

At	O
step	O
t	O
+	O
n	O
+	O
2	O
,	O
neuron	O
uses	O
synapse	O
creation	O
rule	O
a8	O
/	O
a6	O
→	O
+(	O
a6	O
,	O
{	O
l0	O
}),	O
creating	O
a	O
synapse	O
to	O
neuron	O
and	O
sending	O
6	O
spikes	O
to	O
neuron	O
.	O

This	O
means	O
that	O
system	O
Π	O
′	O
starts	O
to	O
simulate	O
the	O
initial	O
instruction	O
l0	O
of	O
register	O
machine	O
M	O
′.	O

Meanwhile	O
,	O
neuron	O
uses	O
synapse	O
deletion	O
rule	O
a8	O
/	O
a	O
→	O
−(	O
λ	O
,	O
{	O
I1	O
}),	O
removing	O
the	O
synapse	O
from	O
neuron	O
..	O
to	O
neuron	O
.	O

In	O
the	O
next	O
step	O
,	O
neuron	O
creates	O
a	O
synapse	O
to	O
neuron	O
σ1	O
and	O
sends	O
5	O
spikes	O
to	O
neuron	O
σ1	O
by	O
using	O
rule	O
a7	O
→	O
+(	O
a5	O
,	O
{	O
1	O
}).	O

From	O
step	O
t	O
+	O
3	O
to	O
t	O
+	O
n	O
+	O
1	O
,	O
neuron	O
σ1	O
receives	O
5	O
spikes	O
in	O
each	O
step	O
from	O
neuron	O
,	O
thus	O
in	O
total	O
accumulating	O
5	O
(	O
n	O
−	O
1	O
)	O
spikes	O
.	O

Neuron	O
σ1	O
receives	O
no	O
spike	O
at	O
step	O
t	O
+	O
n	O
+	O
2	O
,	O
and	O
gets	O
5	O
spikes	O
from	O
neuron	O
at	O
step	O
t	O
+	O
n	O
+	O
3	O
.	O

After	O
that	O
,	O
no	O
more	O
spikes	O
are	O
sent	O
to	O
neuron	O
.	O

Neuron	O
σ1	O
contains	O
5n	O
spikes	O
,	O
which	O
indicates	O
the	O
number	O
to	O
be	O
accepted	O
by	O
register	O
machine	O
M	O
′	O
is	O
n	O
.	O

At	O
step	O
t	O
+	O
n	O
+	O
4	O
,	O
neuron	O
uses	O
rule	O
a2	O
→	O
−(	O
λ	O
,	O
{	O
1	O
}),	O
deleting	O
the	O
synapse	O
to	O
neuron	O
σ1	O
.	O

The	O
dynamic	O
transformation	O
of	O
topological	O
structure	O
of	O
INPUT	O
module	O
and	O
the	O
numbers	O
of	O
spikes	O
in	O
the	O
neurons	O
of	O
INPUT	O
module	O
are	O
shown	O
in	O
Fig	O
.	O
10	O
.	O

The	O
deterministic	O
ADD	O
module	O
is	O
shown	O
in	O
Fig	O
.	O
11	O
,	O
whose	O
function	O
is	O
rather	O
clear	O
.	O

By	O
receiving	O
6	O
spikes	O
,	O
neuron	O
becomes	O
active	O
,	O
creating	O
a	O
synapse	O
and	O
sending	O
5	O
spikes	O
to	O
each	O
of	O
neurons	O
σr	O
,	O
and	O
.	O

The	O
number	O
of	O
spikes	O
in	O
neuron	O
σr	O
is	O
increased	O
by	O
5	O
,	O
which	O
simulates	O
the	O
number	O
stored	O
in	O
register	O
1	O
is	O
increased	O
by	O
one	O
.	O

In	O
the	O
next	O
step	O
,	O
neuron	O
uses	O
rule	O
,	O
removing	O
the	O
synapses	O
from	O
neuron	O
to	O
neurons	O
σr	O
,	O
and	O
.	O

In	O
neurons	O
and	O
,	O
there	O
are	O
5	O
spikes	O
.	O

The	O
two	O
neurons	O
become	O
active	O
by	O
using	O
rule	O
a5	O
/	O
a4	O
→	O
+(	O
a3	O
,	O
{	O
lj	O
}).	O

Each	O
of	O
them	O
creates	O
a	O
synapse	O
to	O
neuron	O
and	O
emits	O
3	O
spikes	O
to	O
neuron	O
.	O

In	O
this	O
way	O
,	O
neuron	O
accumulates	O
6	O
spikes	O
inside	O
,	O
which	O
means	O
the	O
system	O
Π	O
′	O
goes	O
to	O
simulate	O
instruction	O
lj	O
of	O
M	O
′.	O

The	O
synapses	O
from	O
neuron	O
and	O
to	O
neuron	O
will	O
be	O
removed	O
by	O
using	O
synapse	O
deletion	O
rule	O
a	O
→	O
−(	O
λ	O
,	O
{	O
lj	O
})	O
in	O
neurons	O
and	O
.	O

Module	O
SUB	O
remains	O
unchanged	O
,	O
as	O
shown	O
in	O
Fig	O
.	O
4	O
.	O

Module	O
FIN	O
is	O
removed	O
,	O
with	O
neuron	O
remaining	O
in	O
the	O
system	O
,	O
but	O
having	O
no	O
rule	O
inside	O
.	O

When	O
neuron	O
receives	O
6	O
spikes	O
,	O
it	O
means	O
that	O
the	O
computation	O
of	O
register	O
machine	O
M	O
′	O
reaches	O
instruction	O
lh	O
and	O
stops	O
.	O

Having	O
6	O
spikes	O
inside	O
,	O
neuron	O
cannot	O
become	O
active	O
for	O
no	O
rule	O
can	O
be	O
used	O
.	O

In	O
this	O
way	O
,	O
the	O
work	O
of	O
system	O
Π	O
′	O
halts	O
.	O

Based	O
on	O
the	O
description	O
of	O
the	O
implementation	O
of	O
system	O
Π	O
′	O
above	O
,	O
it	O
is	O
clear	O
that	O
the	O
register	O
machine	O
M	O
′	O
in	O
acceptive	O
mode	O
is	O
correctly	O
simulated	O
by	O
the	O
system	O
Π	O
′	O
working	O
in	O
acceptive	O
mode	O
,	O
i	O
.	O
e	O
.,	O
Nacc	O
(	O
M	O
′)	O
=	O
Nacc	O
(	O
Π	O
′).	O

We	O
can	O
check	O
that	O
each	O
neuron	O
in	O
system	O
Π	O
′	O
has	O
at	O
most	O
five	O
rules	O
,	O
and	O
no	O
limit	O
is	O
imposed	O
on	O
the	O
numbers	O
of	O
neurons	O
and	O
the	O
synapses	O
that	O
can	O
be	O
created	O
(	O
or	O
deleted	O
)	O
with	O
using	O
one	O
synapse	O
creation	O
(	O
or	O
deletion	O
)	O
rule	O
.	O

Therefore	O
,	O
it	O
concludes	O
N	O
*	O
SPSOacc	O
(	O
cre	O
*,	O
del	O
*,	O
rule5	O
)	O
=	O
NRE	O
.	O

As	O
function	O
computing	O
device	O

A	O
register	O
machine	O
M	O
can	O
compute	O
a	O
function	O
f	O
:	O
Nk	O
→	O
N	O
as	O
follows	O
:	O
the	O
arguments	O
are	O
introduced	O
in	O
special	O
registers	O
r1	O
,	O
r2	O
,	O
…,	O
rk	O
(	O
without	O
loss	O
of	O
the	O
generality	O
,	O
it	O
is	O
assumed	O
that	O
the	O
first	O
k	O
registers	O
are	O
used	O
).	O

The	O
computation	O
starts	O
with	O
the	O
initial	O
instruction	O
l0	O
.	O
if	O
the	O
register	O
machine	O
halts	O
,	O
i	O
.	O
e	O
.,	O
reaches	O
HALT	O
instruction	O
lh	O
,	O
the	O
value	O
of	O
the	O
function	O
is	O
placed	O
in	O
another	O
specified	O
register	O
,	O
labelled	O
by	O
rt	O
,	O
with	O
all	O
registers	O
different	O
from	O
rt	O
storing	O
number	O
0	O
.	O

The	O
partial	O
function	O
computed	O
by	O
a	O
register	O
machine	O
M	O
in	O
this	O
way	O
is	O
denoted	O
by	O
M	O
(	O
n1	O
,	O
n2	O
,	O
…,	O
nk	O
).	O

All	O
Turing	O
computable	O
functions	O
can	O
be	O
computed	O
by	O
register	O
machine	O
in	O
this	O
way	O
.	O

Several	O
universal	O
register	O
machines	O
for	O
computing	O
functions	O
were	O
defined	O
.	O

Let	O
(	O
φ0	O
,	O
φ1	O
,…)	O
be	O
a	O
fixed	O
admissible	O
enumeration	O
of	O
the	O
unary	O
partial	O
recursive	O
functions	O
.	O

A	O
register	O
machine	O
Mu	O
is	O
said	O
to	O
be	O
universal	O
if	O
there	O
is	O
a	O
recursive	O
function	O
g	O
such	O
that	O
for	O
all	O
natural	O
numbers	O
x	O
,	O
y	O
we	O
have	O
φx	O
(	O
y	O
)	O
=	O
Mu	O
(	O
g	O
(	O
x	O
),	O
y	O
).	O

As	O
addressed	O
by	O
Minsky	O
,	O
universal	O
register	O
machine	O
can	O
compute	O
any	O
φx	O
(	O
y	O
)	O
by	O
inputting	O
a	O
couple	O
of	O
numbers	O
g	O
(	O
x	O
)	O
and	O
y	O
in	O
registers	O
1	O
and	O
2	O
,	O
and	O
the	O
result	O
can	O
be	O
obtained	O
in	O
register	O
047	O
.	O

In	O
the	O
following	O
proof	O
of	O
universality	O
,	O
a	O
specific	O
universal	O
register	O
machine	O
Mu	O
from47	O
is	O
used	O
,	O
the	O
machine	O
Mu	O
=	O
(	O
8	O
,	O
H	O
,	O
l0	O
,	O
lh	O
,	O
I	O
)	O
presented	O
in	O
Fig	O
.	O
12	O
.	O

In	O
this	O
universal	O
register	O
machine	O
Mu	O
,	O
there	O
are	O
8	O
registers	O
(	O
numbered	O
from	O
0	O
to	O
7	O
)	O
and	O
23	O
instructions	O
,	O
and	O
the	O
last	O
instruction	O
is	O
the	O
halting	O
one	O
.	O

As	O
described	O
above	O
,	O
the	O
input	O
numbers	O
(	O
the	O
“	O
code	O
”	O
of	O
the	O
partial	O
recursive	O
function	O
to	O
compute	O
and	O
the	O
argument	O
for	O
this	O
function	O
)	O
are	O
introduced	O
in	O
registers	O
1	O
and	O
2	O
,	O
and	O
the	O
result	O
is	O
outputted	O
in	O
register	O
0	O
when	O
the	O
machine	O
Mu	O
halts	O
.	O

A	O
modification	O
is	O
necessary	O
to	O
be	O
made	O
in	O
Mu	O
,	O
because	O
the	O
subtraction	O
operation	O
in	O
the	O
register	O
where	O
the	O
result	O
is	O
placed	O
is	O
not	O
allowed	O
in	O
the	O
construction	O
of	O
the	O
previous	O
Theorems	O
,	O
but	O
register	O
0	O
of	O
Mu	O
is	O
subject	O
of	O
such	O
operations	O
.	O

That	O
is	O
why	O
an	O
extra	O
register	O
is	O
needed	O
-	O
labeled	O
with	O
8	O
-	O
and	O
the	O
halt	O
instruction	O
lh	O
of	O
Mu	O
should	O
be	O
replaced	O
by	O
the	O
following	O
instructions	O
:	O


Therefore	O
,	O
the	O
modified	O
universal	O
register	O
machine	O
has	O
9	O
registers	O
,	O
24	O
ADD	O
and	O
SUB	O
instructions	O
,	O
and	O
25	O
labels	O
.	O

The	O
result	O
of	O
a	O
computation	O
of	O
is	O
stored	O
in	O
register	O
8	O

Theorem	O
6	O
There	O
is	O
a	O
universal	O
SN	O
P	O
system	O
with	O
self	O
-	O
organization	O
having	O
87	O
neurons	O
for	O
computing	O
functions	O
.	O

Proof	O

An	O
SN	O
P	O
system	O
with	O
self	O
-	O
organization	O
Π	O
″	O
is	O
constructed	O
to	O
simulate	O
the	O
computation	O
of	O
the	O
universal	O
register	O
machine	O
.	O

Specifically	O
,	O
the	O
system	O
Π	O
″	O
consists	O
of	O
deterministic	O
ADD	O
modules	O
,	O
SUB	O
modules	O
,	O
as	O
well	O
as	O
an	O
INPUT	O
module	O
and	O
an	O
OUTPUT	O
module	O
.	O

The	O
deterministic	O
ADD	O
module	O
shown	O
in	O
Fig	O
.	O
11	O
and	O
SUB	O
module	O
shown	O
in	O
Fig	O
.	O
4	O
can	O
be	O
used	O
here	O
to	O
simulate	O
the	O
deterministic	O
ADD	O
instruction	O
and	O
SUB	O
instruction	O
of	O
.	O

The	O
INPUT	O
module	O
introduces	O
the	O
necessary	O
spikes	O
into	O
the	O
system	O
by	O
reading	O
a	O
spike	O
train	O
from	O
the	O
environment	O
,	O
and	O
the	O
OUTPUT	O
module	O
outputs	O
the	O
computation	O
result	O
.	O

With	O
each	O
register	O
r	O
of	O
,	O
a	O
neuron	O
σr	O
in	O
system	O
Π	O
″	O
is	O
associated	O
;	O
the	O
number	O
stored	O
in	O
register	O
r	O
is	O
encoded	O
by	O
the	O
number	O
of	O
spikes	O
in	O
neuron	O
σr	O
.	O

If	O
register	O
r	O
holds	O
the	O
number	O
n	O
≥	O
0	O
,	O
then	O
neuron	O
σr	O
contains	O
5n	O
spikes	O
.	O

With	O
each	O
instruction	O
li	O
in	O
..,	O
a	O
neuron	O
in	O
system	O
Π	O
″	O
is	O
associated	O
.	O

If	O
neuron	O
has	O
6	O
spikes	O
inside	O
,	O
it	O
becomes	O
active	O
and	O
starts	O
to	O
simulate	O
the	O
instruction	O
li	O
.	O

When	O
neuron	O
(	O
associated	O
with	O
the	O
label	O
l	O
′	O
h	O
of	O
the	O
halting	O
instruction	O
of	O
)	O
receives	O
6	O
spikes	O
,	O
the	O
computation	O
in	O
is	O
completely	O
simulated	O
by	O
the	O
system	O
Π	O
″;	O
the	O
number	O
of	O
spikes	O
emitted	O
into	O
the	O
environment	O
from	O
the	O
output	O
neuron	O
,	O
i	O
.	O
e	O
.,	O
neuron	O
σ8	O
,	O
corresponds	O
to	O
the	O
result	O
computed	O
by	O
(	O
stored	O
in	O
register	O
8	O
).	O

The	O
tasks	O
of	O
loading	O
5g	O
(	O
x	O
)	O
spikes	O
in	O
neuron	O
σ1	O
and	O
5y	O
spikes	O
in	O
neuron	O
σ2	O
by	O
reading	O
the	O
spike	O
train	O
10g	O
(	O
x	O
)−	O
110y	O
−	O
11	O
through	O
input	O
neuron	O
σin	O
can	O
be	O
carried	O
out	O
by	O
the	O
INPUT	O
module	O
shown	O
in	O
Fig	O
.	O
13	O
.	O

Initially	O
,	O
all	O
the	O
neurons	O
contain	O
no	O
spike	O
inside	O
,	O
with	O
the	O
exception	O
that	O
neuron	O
σin	O
has	O
15	O
spikes	O
.	O

It	O
is	O
assumed	O
at	O
step	O
t	O
neuron	O
σin	O
reads	O
the	O
first	O
spike	O
from	O
the	O
environment	O
.	O

With	O
16	O
spikes	O
inside	O
,	O
neuron	O
σin	O
becomes	O
active	O
by	O
using	O
rule	O
a16	O
/	O
a6	O
→	O
+(	O
a6	O
,	O
{	O
I1	O
,	O
I2	O
})	O
at	O
step	O
t	O
+	O
1	O
.	O

It	O
creates	O
a	O
synapse	O
and	O
sends	O
6	O
spikes	O
to	O
each	O
of	O
neurons	O
and	O
.	O

Subsequently	O
,	O
neuron	O
σin	O
keeps	O
inactive	O
(	O
for	O
no	O
rule	O
can	O
be	O
used	O
)	O
until	O
the	O
second	O
spike	O
arrives	O
at	O
step	O
t	O
+	O
g	O
(	O
x	O
).	O

Neuron	O
has	O
6	O
spikes	O
and	O
uses	O
rule	O
a6	O
/	O
a	O
→	O
+(	O
λ	O
,	O
{	O
I2	O
,	O
1	O
})	O
at	O
step	O
t	O
+	O
2	O
it	O
creates	O
a	O
synapse	O
to	O
neurons	O
and	O
σ1	O
and	O
sends	O
5	O
spikes	O
to	O
each	O
of	O
the	O
two	O
neurons	O
.	O

Meanwhile	O
,	O
neuron	O
creates	O
a	O
synapse	O
to	O
neuron	O
and	O
sends	O
5	O
spikes	O
to	O
it	O
.	O

From	O
step	O
t	O
+	O
3	O
on	O
,	O
neuron	O
sends	O
5	O
spikes	O
to	O
neuron	O
and	O
exchanges	O
5	O
spikes	O
with	O
neuron	O
in	O
each	O
step	O
.	O

At	O
step	O
t	O
+	O
g	O
(	O
x	O
),	O
neuron	O
σin	O
receives	O
the	O
second	O
spike	O
from	O
the	O
environment	O
.	O

By	O
then	O
it	O
accumulates	O
11	O
spikes	O
inside	O
.	O

At	O
step	O
t	O
+	O
g	O
(	O
x	O
)	O
+	O
1	O
,	O
neuron	O
σin	O
fires	O
by	O
using	O
spiking	O
rule	O
a11	O
/	O
a3	O
→	O
a3	O
,	O
and	O
sends	O
3	O
spikes	O
to	O
neurons	O
and	O
.	O

Each	O
of	O
neurons	O
and	O
..	O
contains	O
8	O
spike	O
,	O
which	O
will	O
be	O
remained	O
in	O
σin	O
.	O

At	O
step	O
t	O
+	O
g	O
(	O
x	O
)	O
+	O
2	O
,	O
neuron	O
applies	O
synapse	O
deletion	O
rule	O
a8	O
/	O
a	O
→	O
−(	O
λ	O
,	O
{	O
I1	O
})	O
and	O
removes	O
the	O
synapse	O
to	O
neuron	O
,	O
meanwhile	O
neuron	O
removes	O
the	O
synapse	O
to	O
neuron	O
.	O

The	O
two	O
neurons	O
stop	O
to	O
exchange	O
spikes	O
with	O
each	O
other	O
.	O

At	O
step	O
t	O
+	O
g	O
(	O
x	O
)	O
+	O
3	O
,	O
neuron	O
has	O
7	O
spikes	O
and	O
fires	O
by	O
using	O
spiking	O
rule	O
a7	O
/	O
a5	O
→	O
a5	O
,	O
and	O
sends	O
5	O
spikes	O
to	O
neuron	O
σ1	O
.	O

In	O
the	O
next	O
step	O
,	O
neuron	O
removes	O
the	O
synapse	O
to	O
neuron	O
σ1	O
,	O
and	O
cannot	O
send	O
spikes	O
to	O
neuron	O
σ1	O
.	O

In	O
general	O
,	O
in	O
each	O
step	O
from	O
step	O
t	O
+	O
3	O
to	O
t	O
+	O
g	O
(	O
x	O
)	O
+	O
1	O
,	O
neuron	O
σ1	O
receives	O
5	O
spikes	O
from	O
neuron	O
,	O
in	O
total	O
receiving	O
5	O
(	O
g	O
(	O
x	O
)	O
−	O
1	O
)	O
spikes	O
;	O
at	O
step	O
t	O
+	O
g	O
(	O
x	O
)	O
+	O
2	O
,	O
no	O
spike	O
arriving	O
in	O
neuron	O
σ1	O
,	O
and	O
at	O
step	O
t	O
+	O
g	O
(	O
x	O
)	O
+	O
3	O
,	O
5	O
spikes	O
reaching	O
neuron	O
σ1	O
.	O

In	O
this	O
way	O
,	O
neuron	O
σ1	O
accumulates	O
5g	O
(	O
x	O
)	O
spikes	O
,	O
which	O
simulates	O
number	O
g	O
(	O
x	O
)	O
is	O
stored	O
in	O
register	O
1	O
of	O
.	O

At	O
step	O
t	O
+	O
g	O
(	O
x	O
)	O
+	O
2	O
,	O
neuron	O
σin	O
contains	O
8	O
spikes	O
such	O
that	O
rule	O
a8	O
/	O
a6	O
→	O
+	O
(	O
a6	O
,	O
{	O
I3	O
,	O
I4	O
})	O
is	O
used	O
,	O
creating	O
a	O
synapse	O
and	O
sends	O
6	O
spikes	O
to	O
each	O
of	O
neurons	O
and	O
.	O

At	O
step	O
t	O
+	O
g	O
(	O
x	O
)	O
+	O
3	O
,	O
neurons	O
and	O
create	O
synapses	O
to	O
each	O
other	O
,	O
meanwhile	O
neuron	O
creates	O
a	O
synapse	O
to	O
neuron	O
σ2	O
.	O

From	O
step	O
t	O
+	O
g	O
(	O
x	O
)	O
+	O
4	O
on	O
,	O
neuron	O
begins	O
to	O
exchange	O
5	O
spikes	O
with	O
and	O
send	O
5	O
spikes	O
to	O
neuron	O
σ2	O
in	O
each	O
step	O
.	O

At	O
step	O
t	O
+	O
g	O
(	O
x	O
)	O
+	O
y	O
,	O
neuron	O
σin	O
receives	O
the	O
third	O
spike	O
from	O
the	O
environment	O
,	O
accumulating	O
3	O
spikes	O
inside	O
.	O

One	O
step	O
later	O
,	O
it	O
fires	O
by	O
using	O
spiking	O
rule	O
a3	O
/	O
a2	O
→	O
a2	O
,	O
sending	O
2	O
spikes	O
to	O
neurons	O
,	O
,	O
and	O
.	O

With	O
2	O
spikes	O
inside	O
,	O
neuron	O
σ1	O
removes	O
its	O
synapse	O
to	O
neuron	O
σ1	O
by	O
rule	O
a2	O
→	O
−(	O
λ	O
,	O
{	O
1	O
});	O
while	O
neuron	O
forgets	O
the	O
two	O
spikes	O
by	O
forgetting	O
rule	O
a2	O
→	O
λ	O
.	O

By	O
receiving	O
2	O
spikes	O
from	O
neuron	O
σin	O
,	O
neurons	O
and	O
contain	O
7	O
spikes	O
.	O

At	O
step	O
t	O
+	O
g	O
(	O
x	O
)	O
+	O
y	O
+	O
2	O
,	O
neuron	O
fires	O
by	O
using	O
rule	O
a7	O
/	O
a3	O
→	O
a3	O
and	O
sends	O
3	O
spikes	O
to	O
neurons	O
σ2	O
and	O
.	O

The	O
number	O
of	O
spikes	O
in	O
neuron	O
σ2	O
is	O
5	O
(	O
y	O
−	O
1	O
)	O
+	O
3	O
.	O

Neuron	O
consumes	O
6	O
spikes	O
,	O
creates	O
a	O
synapse	O
and	O
sends	O
6	O
spikes	O
to	O
neuron	O
.	O

This	O
means	O
system	O
Π	O
''	O
starts	O
to	O
simulate	O
the	O
initial	O
instruction	O
l0	O
of	O
.	O

At	O
step	O
t	O
+	O
g	O
(	O
x	O
)	O
+	O
y	O
+	O
3	O
,	O
neuron	O
has	O
4	O
spikes	O
,	O
and	O
it	O
becomes	O
active	O
by	O
rule	O
a4	O
/	O
a	O
→	O
−(	O
λ	O
,	O
{	O
I4	O
}),	O
and	O
removes	O
its	O
synapse	O
to	O
neuron	O
and	O
ends	O
with	O
3	O
spikes	O
.	O

In	O
the	O
next	O
step	O
,	O
neuron	O
fires	O
by	O
using	O
spiking	O
rule	O
a3	O
/	O
a2	O
→	O
a2	O
,	O
emitting	O
2	O
spikes	O
to	O
neuron	O
σ2	O
.	O

In	O
this	O
way	O
,	O
the	O
number	O
of	O
spikes	O
in	O
neuron	O
σ2	O
becomes	O
5	O
(	O
y	O
−	O
1	O
)	O
+	O
3	O
+	O
2	O
=	O
5y	O
,	O
which	O
indicates	O
number	O
y	O
is	O
stored	O
in	O
register	O
2	O
of	O
.	O

The	O
deterministic	O
ADD	O
module	O
shown	O
in	O
Fig	O
.	O
11	O
and	O
SUB	O
module	O
shown	O
in	O
Fig	O
.	O
4	O
can	O
be	O
used	O
to	O
simulate	O
ADD	O
and	O
SUB	O
instructions	O
of	O
.	O

The	O
FIN	O
module	O
shown	O
in	O
Fig	O
.	O
7	O
can	O
be	O
used	O
to	O
output	O
the	O
computation	O
result	O
with	O
changing	O
neuron	O
σ1	O
into	O
σ8	O
.	O

Until	O
now	O
,	O
we	O
have	O
used	O
9	O
neurons	O
for	O
9	O
registers	O
,	O
25	O
neurons	O
for	O
25	O
labels	O
,	O
20	O
neurons	O
for	O
10	O
ADD	O
instructions	O
,	O
28	O
neurons	O
for	O
14	O
SUB	O
instruction	O
,	O
5	O
additional	O
neurons	O
in	O
the	O
INPUT	O
module	O
,	O

which	O
comes	O
to	O
a	O
total	O
of	O
87	O
neurons	O
.	O

This	O
concludes	O
the	O
proof	O
.	O

Discussion	O
and	O
Future	O
Works	O

In	O
this	O
work	O
,	O
a	O
novel	O
variant	O
of	O
SN	O
P	O
systems	O
,	O
namely	O
SN	O
P	O
systems	O
with	O
self	O
-	O
organization	O
,	O
is	O
introduced	O
.	O

As	O
results	O
,	O
it	O
is	O
proven	O
that	O
the	O
systems	O
are	O
Turing	O
universal	O
,	O
i	O
.	O
e	O
.,	O
they	O
can	O
compute	O
and	O
accept	O
the	O
family	O
of	O
sets	O
of	O
Turing	O
computable	O
natural	O
numbers	O
.	O

With	O
87	O
neurons	O
,	O
the	O
system	O
can	O
compute	O
any	O
Turing	O
computable	O
recursive	O
function	O
,	O
thus	O
achieving	O
Turing	O
universality	O
.	O

There	O
has	O
been	O
a	O
research	O
focus	O
on	O
the	O
construction	O
of	O
small	O
universal	O
SN	O
P	O
with	O
less	O
computing	O
resource	O
,	O
i	O
.	O
e	O
.	O
less	O
number	O
of	O
neuron	O
in	O
use174849505152	O
.	O

It	O
is	O
of	O
interest	O
that	O
whether	O
we	O
can	O
reduce	O
the	O
number	O
of	O
neurons	O
in	O
universal	O
SN	O
P	O
systems	O
with	O
self	O
-	O
organization	O
as	O
function	O
computing	O
devices	O
.	O

A	O
possible	O
way	O
is	O
to	O
construct	O
ADD	O
-	O
ADD	O
,	O
ADD	O
-	O
SUB	O
and	O
SUB	O
-	O
ADD	O
modules	O
to	O
perform	O
particular	O
consecutive	O
ADD	O
-	O
ADD	O
,	O
ADD	O
-	O
SUB	O
,	O
and	O
SUB	O
-	O
ADD	O
instructions	O
of	O
.	O

SN	O
P	O
systems	O
with	O
learning	O
function	O
/	O
capabiliy	O
is	O
a	O
promising	O
direction	O
.	O

Learning	O
strategies	O
and	O
feedback	O
mechanism	O
have	O
been	O
intensively	O
studied	O
and	O
investigated	O
in	O
conventional	O
artificial	O
neural	O
networks	O
.	O

It	O
is	O
worthy	O
to	O
look	O
into	O
these	O
techniques	O
and	O
transplant	O
these	O
ideas	O
into	O
SN	O
P	O
systems	O
with	O
self	O
-	O
organization	O
.	O

In	O
research	O
of	O
using	O
artificial	O
neural	O
networks	O
to	O
recognize	O
digital	O
English	O
letters	O
,	O
database	O
MNIST	O
(	O
Mixed	O
National	O
Institute	O
of	O
Standards	O
and	O
Technology	O
database	O
)	O
is	O
widely	O
used	O
for	O
training	O
various	O
letter	O
recognition	O
systems53	O
,	O
and	O
for	O
training	O
and	O
testing	O
in	O
the	O
field	O
of	O
machine	O
learning54	O
.	O

For	O
further	O
research	O
,	O
SN	O
P	O
systems	O
with	O
self	O
-	O
organization	O
may	O
be	O
used	O
to	O
recognize	O
handwritten	O
digits	O
letters	O
and	O
other	O
possible	O
pattern	O
recognition	O
problems	O
.	O

Since	O
the	O
data	O
structure	O
of	O
SN	O
P	O
systems	O
is	O
binary	O
sequences	O
,	O
an	O
extra	O
task	O
of	O
transmitting	O
letters	O
or	O
pictures	O
into	O
binary	O
sequences	O
should	O
be	O
addressed	O
.	O

A	O
possible	O
way	O
is	O
transmitting	O
digital	O
numbers	O
of	O
pixels	O
of	O
pictures	O
to	O
binary	O
form	O
.	O

Also	O
,	O
local	O
binary	O
pattern	O
method	O
,	O
can	O
be	O
used	O
to	O
transmit	O
pictures	O
to	O
binary	O
forms	O
.	O

Bioinformatics	O
is	O
s	O
an	O
interdisciplinary	O
field	O
that	O
develops	O
methods	O
and	O
software	O
tools	O
for	O
understanding	O
biological	O
data55	O
.	O

Artificial	O
intelligence	O
based	O
methods	O
and	O
data	O
mining	O
strategy	O
have	O
been	O
used	O
in	O
processing	O
biological	O
data	O
,	O
see	O
e	O
.	O
g	O
.	O
56575859606162	O
,	O
it	O
is	O
worthy	O
to	O
processing	O
biological	O
data	O
by	O
SN	O
P	O
systems	O
,	O
such	O
as	O
DNA	O
motif	O
finding6364	O
,	O
nuclear	O
export	O
signal	O
identification6566	O
.	O

Additional	O
Information	O

How	O
to	O
cite	O
this	O
article	O
:	O
Wang	O
,	O
X	O
.	O
et	O
al	O
.	O

On	O
the	O
Computational	O
Power	O
of	O
Spiking	O
Neural	O
P	O
Systems	O
with	O
Self	O
-	O
Organization	O
.	O
Sci	O
.	O

Rep	O
.	O
6	O
,	O
27624	O
;	O
doi	O
:	O
10	O
.	O
1038	O
/	O
srep27624	O
(	O
2016	O
).	O

Author	O
Contributions	O
T	O
.	O
S	O
.	O
and	O
X	O
.	O
W	O
.	O
contributed	O
the	O
main	O
idea	O
,	O
X	O
.	O
W	O
.	O
and	O
F	O
.	O
G	O
.	O
performed	O
the	O
analysis	O
and	O
theoretical	O
proofs	O
,	O
P	O
.	O
Z	O
.	O
and	O
X	O
.	O
W	O
.	O
wrote	O
the	O
paper	O
.	O

All	O
authors	O
reviewed	O
the	O
manuscript	O
.	O


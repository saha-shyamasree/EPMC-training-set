<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName A++V2.4.dtd?><?SourceDTD.Version 2.4?><?ConverterInfo.XSLTName springer2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">BMC Med Res Methodol</journal-id><journal-id journal-id-type="iso-abbrev">BMC Med Res Methodol</journal-id><journal-title-group><journal-title>BMC Medical Research Methodology</journal-title></journal-title-group><issn pub-type="epub">1471-2288</issn><publisher><publisher-name>BioMed Central</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">5217317</article-id><article-id pub-id-type="publisher-id">277</article-id><article-id pub-id-type="doi">10.1186/s12874-016-0277-1</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group></article-categories><title-group><article-title><SecTag type="TITLE"><text><SENT sid="0" pm="."><plain>Clinical prediction in defined populations: a simulation study investigating when and how to aggregate existing models </plain></SENT>
</text></SecTag></article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Martin</surname><given-names>Glen P.</given-names></name><address><phone>0161 306 0679</phone><email>glen.martin@manchester.ac.uk</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Mamas</surname><given-names>Mamas A.</given-names></name><address><email>mamasmamas1@yahoo.co.uk</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Peek</surname><given-names>Niels</given-names></name><address><email>niels.peek@manchester.ac.uk</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author"><name><surname>Buchan</surname><given-names>Iain</given-names></name><address><email>Buchan@manchester.ac.uk</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author"><name><surname>Sperrin</surname><given-names>Matthew</given-names></name><address><email>matthew.sperrin@manchester.ac.uk</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><aff id="Aff1"><label>1</label>Health e-Research Centre, University of Manchester, Vaughan House, Portsmouth Street, M13 9GB Manchester, UK </aff><aff id="Aff2"><label>2</label>Keele Cardiovascular Research Group, Keele University, Stoke-on-Trent, UK </aff><aff id="Aff3"><label>3</label>NIHR Greater Manchester Primary Care Patient Safety Translational Research Centre, University of Manchester, Manchester, UK </aff></contrib-group><pub-date pub-type="epub"><day>6</day><month>1</month><year>2017</year></pub-date><pub-date pub-type="pmc-release"><day>6</day><month>1</month><year>2017</year></pub-date><pub-date pub-type="collection"><year>2017</year></pub-date><volume>17</volume><elocation-id>1</elocation-id><history><date date-type="received"><day>17</day><month>8</month><year>2016</year></date><date date-type="accepted"><day>15</day><month>12</month><year>2016</year></date></history><permissions><copyright-statement>© The Author(s). 2017</copyright-statement><license license-type="OpenAccess"><license-p>
<bold>Open Access</bold>This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p></license></permissions><abstract id="Abs1"><sec><title><text><SENT sid="1" pm="."><plain>Background </plain></SENT>
</text></title><p><SecTag type="ABS"><text><SENT sid="2" pm="."><plain>Clinical prediction models (CPMs) are increasingly deployed to support healthcare decisions but they are derived inconsistently, in part due to limited data. </plain></SENT>
<SENT sid="3" pm="."><plain>An emerging alternative is to aggregate existing CPMs developed for similar settings and outcomes. </plain></SENT>
<SENT sid="4" pm="."><plain>This simulation study aimed to investigate the impact of between-population-heterogeneity and sample size on aggregating existing CPMs in a defined population, compared with developing a model de novo. </plain></SENT>
</text></SecTag></p></sec><sec><title><text><SENT sid="5" pm="."><plain>Methods </plain></SENT>
</text></title><p><SecTag type="ABS"><text><SENT sid="6" pm="."><plain>Simulations were designed to mimic a scenario in which multiple CPMs for a binary outcome had been derived in distinct, heterogeneous populations, with potentially different predictors available in each. </plain></SENT>
<SENT sid="7" pm="."><plain>We then generated a new ‘local’ population and compared the performance of CPMs developed for this population by aggregation, using stacked regression, principal component analysis or partial least squares, with redevelopment from scratch using backwards selection and penalised regression. </plain></SENT>
</text></SecTag></p></sec><sec><title><text><SENT sid="8" pm="."><plain>Results </plain></SENT>
</text></title><p><SecTag type="ABS"><text><SENT sid="9" pm="."><plain>While redevelopment approaches resulted in models that were miscalibrated for local datasets of less than 500 observations, model aggregation methods were well calibrated across all simulation scenarios. </plain></SENT>
<SENT sid="10" pm="."><plain>When the size of local data was less than 1000 observations and between-population-heterogeneity was small, aggregating existing CPMs gave better discrimination and had the lowest mean square error in the predicted risks compared with deriving a new model. </plain></SENT>
<SENT sid="11" pm="."><plain>Conversely, given greater than 1000 observations and significant between-population-heterogeneity, then redevelopment outperformed the aggregation approaches. </plain></SENT>
<SENT sid="12" pm="."><plain>In all other scenarios, both aggregation and de novo derivation resulted in similar predictive performance. </plain></SENT>
</text></SecTag></p></sec><sec><title><text><SENT sid="13" pm="."><plain>Conclusion </plain></SENT>
</text></title><p><SecTag type="ABS"><text><SENT sid="14" pm="."><plain>This study demonstrates a pragmatic approach to contextualising CPMs to defined populations. </plain></SENT>
<SENT sid="15" pm="."><plain>When aiming to develop models in defined populations, modellers should consider existing CPMs, with aggregation approaches being a suitable modelling strategy particularly with sparse data on the local population. </plain></SENT>
</text></SecTag></p></sec><sec><title><text><SENT sid="16" pm="."><plain>Electronic supplementary material </plain></SENT>
</text></title><p><SecTag type="ABS"><text><SENT sid="17" pm="."><plain>The online version of this article (doi:10.1186/s12874-016-0277-1) contains supplementary material, which is available to authorized users. </plain></SENT>
</text></SecTag></p></sec></abstract><SecTag type="KEYWORD"><kwd-group xml:lang="en"><title>Keywords</title><kwd>Clinical prediction models</kwd><kwd>Model aggregation</kwd><kwd>Validation</kwd><kwd>Computer simulation</kwd><kwd>Contextual heterogeneity</kwd></kwd-group></SecTag><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000265</institution-id><institution>Medical Research Council</institution></institution-wrap></funding-source><award-id>[MR/K006665/1]</award-id><principal-award-recipient><name><surname>Martin</surname><given-names>Glen P.</given-names></name></principal-award-recipient></award-group></funding-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>© The Author(s) 2017</meta-value></custom-meta></custom-meta-group></article-meta></front><body><SecTag type="INTRO"><sec id="Sec1"><title><text><SENT sid="18" pm="."><plain>Background </plain></SENT>
</text></title><p><text><SENT sid="19" pm="."><plain>Clinical prediction models (CPMs), which compute the risk of an outcome for a given set of patient characteristics, are fundamental to clinical decision support systems. </plain></SENT>
<SENT sid="20" pm="."><plain>For instance, practical uses of CPMs include facilitating discussions about the risks associated with a proposed treatment strategy, assisting audit analyses and benchmarking post-procedural outcomes. </plain></SENT>
<SENT sid="21" pm="."><plain>Consequently, there is growing interest in developing CPMs to support local healthcare decisions [1, 2]. </plain></SENT>
<SENT sid="22" pm="."><plain>Although there might be existing models derived for similar outcomes and populations, it is vital they are appropriately updated, validated and transferred between different contexts of use. </plain></SENT>
<SENT sid="23" pm="."><plain>Baseline risk and predictor effects may differ across populations, which can cause model performance to decrease when transferring an existing CPM to the local population [3–6]. </plain></SENT>
<SENT sid="24" pm="."><plain>This between-population-heterogeneity frequently leads to researchers rejecting existing models and developing new ones [5, 7–10]. </plain></SENT>
<SENT sid="25" pm="."><plain>However, this framework is undesirable because the dataset used to derive the new CPM is often smaller than previous derivation datasets and can lead to multiple models for the same outcome. </plain></SENT>
<SENT sid="26" pm="."><plain>For instance, over 60 previously published models predict breast cancer [11], which is perplexing and unhelpful to end-users. </plain></SENT>
</text></p><p><text><SENT sid="27" pm="."><plain>As a motivating example, consider a user wishing to predict short-term mortality post cardiac-surgery. </plain></SENT>
<SENT sid="28" pm="."><plain>There are several existing CPMs available, including the Logistic EuroSCORE (LES), the EuroSCORE II (ESII), the STS score and the German Aortic Valve Model (German AV) [12–16]. </plain></SENT>
<SENT sid="29" pm="."><plain>These models share some common predictors, for example gender, arterial disease outside the heart and recent heart attack, but some predictors appear only in a subset of the CPMs. </plain></SENT>
<SENT sid="30" pm="."><plain>For instance, diabetes is only incorporated into the ESII and STS models, while atrial fibrillation is only in the STS and German AV models. </plain></SENT>
<SENT sid="31" pm="."><plain>Moreover, definitions and coding of some predictors could differ: examples include left ventricular ejection fraction and age. </plain></SENT>
</text></p><p><text><SENT sid="32" pm="."><plain>While differences in variable definitions between existing CPMs add complexity, the prior information encapsulated by each model can be exploited. </plain></SENT>
<SENT sid="33" pm="."><plain>A generalizable existing CPM could serve as an informative prior for a new population; for example, by transferring information regarding likely covariate-outcome relations, as in stacked regression [9, 17]. </plain></SENT>
<SENT sid="34" pm="."><plain>However, there has been limited investigation into the impact of sample size and between-population-heterogeneity on the performance of model aggregation versus deriving a new CPM. </plain></SENT>
</text></p><p><text><SENT sid="35" pm="."><plain>This simulation study considers a situation in which there is a new (local) population, with associated data, and interest lies in developing a CPM for it. </plain></SENT>
<SENT sid="36" pm="."><plain>The modeller must make a choice between utilising existing CPMs that have been developed in different populations, developing a new model and disregarding existing ones, or some mixture of the two [18]. </plain></SENT>
<SENT sid="37" pm="."><plain>We hypothesised that the modelling strategy that optimised performance would depend on: 1) the degree of variation in risk across multiple populations (between-population-heterogeneity); and 2) the quantity of data available in the local population, relative to the size of previous derivation datasets. </plain></SENT>
</text></p></sec></SecTag><SecTag type="METHODS"><sec id="Sec2"><title><text><SENT sid="38" pm="."><plain>Methods </plain></SENT>
</text></title><p><text><SENT sid="39" pm="."><plain>Throughout this study, all CPMs will be assumed to be logistic regression models, although the techniques apply to other types of prediction model, such as those for time-to-event outcomes. </plain></SENT>
<SENT sid="40" pm="."><plain>Stacked regression (SR) [9, 17], principal component analysis (PCA) [19, 20] and partial least squares (PLS) are three possible methods that simultaneously aggregate and calibrate existing models to a new population. </plain></SENT>
<SENT sid="41" pm="."><plain>We describe SR and PCA here, with PLS described in Additional file 1. </plain></SENT>
<SENT sid="42" pm="."><plain>This study compares the three aforementioned aggregate approaches with deriving a new model; possible techniques of redevelopment are also outlined in this section. </plain></SENT>
</text></p><sec id="Sec3"><title><text><SENT sid="43" pm="."><plain>Model aggregation: stacked regression </plain></SENT>
</text></title><p><text><SENT sid="44" pm="."><plain>Consider a collection of M existing logistic regression CPMs, which all aim to predict the same binary outcome but were derived in different populations, j = 1, …, M. </plain></SENT>
<SENT sid="45" pm="."><plain>For a set of observations i = 1, …, n j from population j, let X j denote the n j × P matrix of predictors that are potentially associated with the outcome, Y j. </plain></SENT>
<SENT sid="46" pm="."><plain>Here, P represents the number of predictors available across all populations; a predictor that is not present in a given CPM simply has coefficient zero. </plain></SENT>
<SENT sid="47" pm="."><plain>Then, for i = 1, …, n j, the linear predictor (LP) from the j th existing CPM, LPi,j, is given by\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$ {\mathrm{LP}}_{i,j} = {\beta}_{0,j}+{\displaystyle \sum_{p=1}^P}{\beta}_{p,j}{x}_{i,p} $$\end{document}LPi,j=β0,j+∑p=1Pβp,jxi,p </plain></SENT>
</text></p><p><text><SENT sid="48" pm="."><plain>with intercept β 0,j and coefficients β 1,j, …, β P,j, at least one of which is non-zero. </plain></SENT>
</text></p><p><text><SENT sid="49" pm="."><plain>Suppose we then have a new local population, j = M + 1. </plain></SENT>
<SENT sid="50" pm="."><plain>Stacked regression aims to weight the M linear predictors (calculated for each observation in the new local population) to maximise the logistic regression likelihood. </plain></SENT>
<SENT sid="51" pm="."><plain>Specifically, SR assumes that for i = 1, …, n M + 1, Y i,M + 1 ∼ Bernoulli(πi,M + 1) where π i,M + 1 = P(Y i,M + 1 = 1) with\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$ \log \left(\frac{\pi_{i,M+1}}{1-{\pi}_{i,M+1}}\right)={\widehat{\gamma}}_0+{\displaystyle \sum_{j=1}^M}{\widehat{\gamma}}_j{\mathrm{LP}}_{i,j} $$\end{document}logπi,M+11−πi,M+1=γ^0+∑j=1Mγ^jLPi,j </plain></SENT>
</text></p><p><text><SENT sid="52" pm="."><plain>under the constraint that \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$ {\widehat{\gamma}}_1,\dots,\ {\widehat{\gamma}}_M\ge 0 $$\end{document}γ^1,…,γ^M≥0 to account for collinearity between the existing CPMs. </plain></SENT>
<SENT sid="53" pm="."><plain>Here, LPi,j denotes the linear predictor from the j th existing CPM calculated for observation i ∈ [1, n M + 1] in the new local population. </plain></SENT>
<SENT sid="54" pm="."><plain>Thus, we have\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$ \log \left(\frac{\pi_{i,M+1}}{1-{\pi}_{i,M+1}}\right) = {\widehat{\gamma}}_0+{\displaystyle \sum_{j=1}^M}{\widehat{\gamma}}_j{\beta}_{0,j} + {\displaystyle \sum_{p=1}^P}{\displaystyle \sum_{j=1}^M}{\widehat{\gamma}}_j{\beta}_{p,j}{x}_{i,p}, $$\end{document}logπi,M+11−πi,M+1=γ^0+∑j=1Mγ^jβ0,j+∑p=1P∑j=1Mγ^jβp,jxi,p, </plain></SENT>
</text></p><p><text><SENT sid="55" pm="."><plain>which can be used to calculate subsequent risk predictions for a new observation. </plain></SENT>
<SENT sid="56" pm="."><plain>The hat accent above parameters indicates those that are estimated from the local population data. </plain></SENT>
<SENT sid="57" pm="."><plain>Specifically, SR estimates \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$ {\widehat{\gamma}}_j $$\end{document}γ^j but not β p,j, which are taken as fixed values from the published existing CPM. </plain></SENT>
</text></p></sec><sec id="Sec4"><title><text><SENT sid="58" pm="."><plain>Model aggregation: Principal Components Analysis (PCA) regression </plain></SENT>
</text></title><p><text><SENT sid="59" pm="."><plain>Let LP denote the n M + 1 × M matrix, with (i, j)th element being the linear predictor for the j th existing CPM calculated for observations i = 1, …, n M + 1 in the local population. </plain></SENT>
<SENT sid="60" pm="."><plain>The singular value decomposition of LP gives an M × M rotation matrix, ν. </plain></SENT>
<SENT sid="61" pm="."><plain>Multiplying LP by ν, gives the n M + 1 × M matrix of principal components, Z. </plain></SENT>
<SENT sid="62" pm="."><plain>PCA regression again assumes that Y i,M + 1 ∼ Bernoulli(π i,M + 1) for i = 1, …, n M + 1 with\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$ \log \left(\frac{\pi_{i,M+1}}{1-{\pi}_{i,M+1}}\right)={\widehat{\theta}}_0+{\displaystyle \sum_{j=1}^M}{\widehat{\theta}}_j{Z}_{i,j}. $$\end{document}logπi,M+11−πi,M+1=θ^0+∑j=1Mθ^jZi,j. </plain></SENT>
</text></p><p><text><SENT sid="63" pm="."><plain>Unlike in SR, no restrictions are placed on the parameters \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$ {\widehat{\theta}}_j $$\end{document}θ^j since, by definition, the principal components, Z, are uncorrelated. </plain></SENT>
<SENT sid="64" pm="."><plain>One can obtain predictions for a future observation by converting the above aggregate model onto the scale of the original risk factors,\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$ \log \left(\frac{\pi_{i,M+1}}{1-{\pi}_{i,M+1}}\right)={\widehat{\theta}}_0+{\displaystyle \sum_{j=1}^M}{\widehat{\theta}}_j\left(L{P}_{i,1}{v}_{1,j}+\dots +L{P}_{i,M}{v}_{M,j}\right)={\widehat{\theta}}_0+{\displaystyle \sum_{j=1}^M}{\displaystyle \sum_{r=1}^M}{\widehat{\theta}}_j{v}_{r,j}L{P}_{i,r}. $$\end{document}logπi,M+11−πi,M+1=θ^0+∑j=1Mθ^jLPi,1v1,j+…+LPi,MvM,j=θ^0+∑j=1M∑r=1Mθ^jvr,jLPi,r. </plain></SENT>
</text></p></sec><sec id="Sec5"><title><text><SENT sid="65" pm="."><plain>Model redevelopment </plain></SENT>
</text></title><p><text><SENT sid="66" pm="."><plain>Let X M + 1 denote the n M + 1 × P matrix of predictors in the local population with associated binary outcomes Y M + 1. </plain></SENT>
<SENT sid="67" pm="."><plain>Then the redevelopment approaches aim to derive a new CPM of the form\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$ \log \left(\frac{\pi_{i,M+1}}{1-{\pi}_{i,M+1}}\right) = {\widehat{\beta}}_{0,M+1}+{\displaystyle \sum_{p=1}^P}{\widehat{\beta}}_{p,M+1}{x}_{i,p} $$\end{document}logπi,M+11−πi,M+1=β^0,M+1+∑p=1Pβ^p,M+1xi,p </plain></SENT>
</text></p><p><text><SENT sid="68" pm="."><plain>for i = 1, …, n M + 1, model intercept, \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$ {\widehat{\beta}}_{0,M+1} $$\end{document}β^0,M+1, and coefficients, \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$ {\widehat{\beta}}_{p,M+1} $$\end{document}β^p,M+1, thereby disregarding the existing CPMs. </plain></SENT>
<SENT sid="69" pm="."><plain>In this study, two strategies of redevelopment were considered; namely, backwards selection using Akaike Information Criterion (AIC) and penalised maximum likelihood estimation (ridge regression). </plain></SENT>
<SENT sid="70" pm="."><plain>The AIC of a model is defined as 2k − 2 log(L), where k is the number of estimated parameters and L is the maximum likelihood value. </plain></SENT>
<SENT sid="71" pm="."><plain>Backwards selection under AIC proceeds by starting with the full model (i.e. all available predictors) and iteratively removing predictors until the model that minimises the AIC is obtained. </plain></SENT>
<SENT sid="72" pm="."><plain>Conversely, ridge regression estimates the coefficients from the full model by maximising the following penalised log-likelihood function\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$ {l}^{*}\left({\widehat{\beta}}_{M+1}\right)=\left({\displaystyle \sum_{i=1}^{n_{M+1}}}\left\{{y}_i \log \left({\pi}_{i,M+1}\right)+\left(1-{y}_i\right) \log \left(1-{\pi}_{i,M+1}\right)\right\}\right)-\lambda \left({\displaystyle \sum_{p=1}^P}{\left({\widehat{\beta}}_{p,M+1}\right)}^2\right). $$\end{document}l*β^M+1=∑i=1nM+1yilogπi,M+1+1−yilog1−πi,M+1−λ∑p=1Pβ^p,M+12. </plain></SENT>
</text></p><p><text><SENT sid="73" pm="."><plain>Thus, the penalty shrinks the model coefficients towards zero, with λ controlling the degree of penalisation; cross-validation was used to select λ that minimised the deviance function. </plain></SENT>
</text></p></sec><sec id="Sec6"><title><text><SENT sid="74" pm="."><plain>Simulation design: general overview </plain></SENT>
</text></title><p><text><SENT sid="75" pm="."><plain>Figure 1 visualises the simulation design. </plain></SENT>
<SENT sid="76" pm="."><plain>The simulation procedure generated both Normally distributed continuous predictors and Bernoulli distributed binary predictors, each within clusters of serially correlated variables to represent multiple risk factors that measure similar patient characteristics. </plain></SENT>
<SENT sid="77" pm="."><plain>Such data were row partitioned into M = 5 distinct subsets of size n exist = 5000 representing five “existing populations”, and one subset of size n local representing the “local population”. </plain></SENT>
<SENT sid="78" pm="."><plain>The M = 5 existing populations were each used to fit an existing logistic regression CPMs representing those available from the literature, with each CPM including a potentially overlapping subset of risk predictors (see Additional file 1: Table S1 for details of predictor selection for the existing CPMs). </plain></SENT>
<SENT sid="79" pm="."><plain>The single local population was randomly split into a training and validation set, of sizes n train and n validate, respectively (i.e. n local = n train + n validate). </plain></SENT>
<SENT sid="80" pm="."><plain>The training set was used for model aggregation using SR, PCA and PLS in addition to redevelopment using AIC and ridge regression. </plain></SENT>
<SENT sid="81" pm="."><plain>Datasets frequently only collect a subset of the potential risk factors; to recognise this, exactly those predictors that were included in any of the five existing CPMs were considered candidates during redevelopment. </plain></SENT>
<SENT sid="82" pm="."><plain>Between simulations n train was varied through (150, 250, 500, 1000, 5000, 10000); the validation set was reserved only to validate the models with n validate fixed at 5000 observations. </plain></SENT>
<SENT sid="83" pm="."><plain>Whilst it is unlikely that local populations would have access to such a large validation set, this was selected here to give sufficient event numbers for an accurate assessment of model performance [21–23]. </plain></SENT>
<SENT sid="84" pm="."><plain>Additionally, although bootstrapping methods are preferable to assess model performance in real-world datasets, the split-sample method was employed here for simplicity and clear illustration of the methods [24].Fig. 1Simulation Procedure: A pictorial representation of the simulation procedure for a given value of population heterogeneity, σ, and a given development sample size, n train. </plain></SENT>
<SENT sid="85" pm="."><plain>This process was then repeated across all combinations of σ and n train  </plain></SENT>
</text></p><p><text><SENT sid="86" pm="."><plain>Binary responses were simulated in all populations with probability calculated from a population-specific generating logistic regression model, which included a subset of the simulated risk predictors. </plain></SENT>
<SENT sid="87" pm="."><plain>The coefficients of each population-specific generating model were sampled from a normal distribution, with a common mean across populations and variance σ. </plain></SENT>
<SENT sid="88" pm="."><plain>Here, higher values of σ induced greater differences in predictor effects across populations and thus represented increasing between-population-heterogeneity. </plain></SENT>
<SENT sid="89" pm="."><plain>For each of the aforementioned values of n train, simulations were run with σ values of (0, 0.125, 0.25, 0.375, 0.5, 0.75, 1). </plain></SENT>
</text></p><p><text><SENT sid="90" pm="."><plain>Across every combination of σ and n train, the simulation was repeated over 1000 iterations as a compromise between estimator accuracy and computational time. </plain></SENT>
<SENT sid="91" pm="."><plain>The simulations were implemented using R version 3.2.5 [25]. </plain></SENT>
<SENT sid="92" pm="."><plain>The following packages were used in the simulation: “pROC” [26] to calculate the AUC of each model, “plsRglm” [27] to fit the PLS models and the “cv.glmnet” function within the “glmnet” package for deriving a new model by cross-validated ridge regression [28]. </plain></SENT>
<SENT sid="93" pm="."><plain>The authors wrote all other code, which is available in Additional file 1. </plain></SENT>
</text></p></sec><sec id="Sec7"><title><text><SENT sid="94" pm="."><plain>Simulation design: data-generating mechanisms </plain></SENT>
</text></title><p><text><SENT sid="95" pm="."><plain>In practice, modellers could define any one risk factor through different but potentially related variables and multiple risk factors within a model could be correlated. </plain></SENT>
<SENT sid="96" pm="."><plain>Hence, the simulation procedure generated risk predictors within clusters of serially correlated variables. </plain></SENT>
<SENT sid="97" pm="."><plain>Specifically, P = 50 predictors were generated within 10 clusters, so that each cluster included K = 5 predictors. </plain></SENT>
<SENT sid="98" pm="."><plain>Predictors had serial correlation within each cluster but were independent between clusters. </plain></SENT>
<SENT sid="99" pm="."><plain>To represent common real data structures, the simulation generated clusters of binary and continuous predictors in an approximately 50/50 split, with the ‘type’ of each cluster decided at random before each simulation. </plain></SENT>
<SENT sid="100" pm="."><plain>For simplicity, clusters did not ‘mix’ binary and continuous variables. </plain></SENT>
<SENT sid="101" pm="."><plain>If X N × P denotes the N × P matrix of predictors (where N is the cumulative sample size across all populations) and ρ denotes the within-cluster correlation, then the process to generate the predictors was adapted from previous studies [29] as follows:If cluster κ includes only continuous predictors then simulate N realisations of the predictors at the ‘start’ of the cluster as\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$ {\boldsymbol{X}}_p\sim \mathrm{Normal}\left(0,1\right), $$\end{document}Xp∼Normal01, and simulate the remaining K-1 correlated predictors as\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$ {\boldsymbol{X}}_p\sim \rho {\boldsymbol{X}}_{p-1}+\sqrt{\left(1-{\rho}^2\right)}\boldsymbol{\Psi}, $$\end{document}Xp∼ρXp−1+1−ρ2Ψ, where Ψ ∼ Normal(0, 1).Else, if cluster κ includes only binary predictors, we generate them as latent Normal. </plain></SENT>
<SENT sid="102" pm="."><plain>Specifically, simulate N realisations of the predictors at the ‘start’ of each cluster as\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$ {\boldsymbol{X}}_p\sim \mathrm{Normal}\left(0,1\right), $$\end{document}Xp∼Normal01, and simulate the remaining K-1 correlated predictors as\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$ {\boldsymbol{X}}_p\sim \left\{\begin{array}{c}\hfill {\boldsymbol{X}}_{p-1}\ \mathrm{with}\ \mathrm{prob}.\ \rho \hfill \\ {}\hfill \boldsymbol{\Psi}\ \mathrm{with}\ \mathrm{prob}.\ 1-\rho \hfill \end{array}\right. $$\end{document}Xp∼Xp−1withprob.ρΨwithprob.1−ρ where Ψ ∼ Normal(0, 1). </plain></SENT>
<SENT sid="103" pm="."><plain>Each variable in the cluster was then dichotomized to give a pre-defined cluster-specific event rate between 10 and 50%, which are values frequently reported in observational datasets.Repeat steps 1 to 2 across all κ = 10 clusters. </plain></SENT>
</text></p><p><text><SENT sid="104" pm="."><plain>Sensitivity analyses across a range of within-cluster correlations, ρ ∈ [0, 0.99] showed that the results were qualitatively similar; the results given are for ρ = 0.75. </plain></SENT>
</text></p><p><text><SENT sid="105" pm="."><plain>Binary responses for individuals i = 1, …, n j in population j were sampled from a population-specific generating logistic regression model with P(Y i,j = 1) = q i,j, where\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$ \log \left(\frac{q_{i,j}}{1-{q}_{i,j}}\right)={\alpha}_{0,j} + {\displaystyle \sum_{p=1}^{P=50\ }}{\alpha}_{p,j}{\mathrm{x}}_{i,p} $$\end{document}logqi,j1−qi,j=α0,j+∑p=1P=50αp,jxi,p </plain></SENT>
</text></p><p><text><SENT sid="106" pm="."><plain>with intercept α 0,j and generating coefficients α 1,j, …, α 50,j. </plain></SENT>
<SENT sid="107" pm="."><plain>If \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$ \overline{\boldsymbol{\alpha}} $$\end{document}α¯ represents the vector of mean predictor effects across all populations, then the simulation mechanism in each population j and generating parameter p = 1, …, 50 was\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$ {\alpha}_{p,j}\sim \left\{\begin{array}{cc}\hfill \mathrm{N}\left({\overline{\alpha}}_p,{\upsigma}^2\right)\hfill &amp; \hfill \mathrm{if}\ p\equiv 1\ \left( \mod\ \mathrm{K}=5\right)\hfill \\ {}\hfill 0\hfill &amp; \hfill \mathrm{otherwise}\hfill \end{array}\right. $$\end{document}αp,j∼Nα¯pσ2ifp≡1modK=50otherwise </plain></SENT>
</text></p><p><text><SENT sid="108" pm="."><plain>The p≡1 (mod K = 5) condition implies (without loss of generality) that in each population, all non-zero generating coefficients were those at the ‘start’ of each cluster. </plain></SENT>
<SENT sid="109" pm="."><plain>Further, such a simulation procedure induced between-population-heterogeneity by applying random variation to the mean predictor-effects (\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$ \overline{\boldsymbol{\alpha}} $$\end{document}α¯), which was controlled through the value of σ that was introduced above. </plain></SENT>
<SENT sid="110" pm="."><plain>To represent coefficients frequently reported in published models, \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$ \overline{\boldsymbol{\alpha}} $$\end{document}α¯ was sampled in each simulation as follows:\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$ {\overline{\alpha}}_p\sim \left\{\begin{array}{cc}\hfill \mathrm{Uniform}\left(0.80,\ 1.6\right)\hfill &amp; \hfill \mathrm{if}\ \mathrm{parameter}\ p\ \mathrm{is}\ \mathrm{binary}\hfill \\ {}\hfill \mathrm{Uniform}\left(0.08,\ 0.1\right)\hfill &amp; \hfill \mathrm{if}\ \mathrm{parameter}\ p\ \mathrm{is}\ \mathrm{continuous}\hfill \end{array}\right. $$\end{document}α¯p∼Uniform0.80,1.6ifparameterpisbinaryUniform0.08,0.1ifparameterpiscontinuous </plain></SENT>
</text></p><p><text><SENT sid="111" pm="."><plain>In addition, baseline risk undoubtedly differs between populations and, as such, each intercept α 0,j was selected to give an average pre-defined event rate of 20% plus random variation. </plain></SENT>
<SENT sid="112" pm="."><plain>All simulations were repeated with an event rate of 50%, reflecting a 1-to-1 case-control study. </plain></SENT>
<SENT sid="113" pm="."><plain>A sensitivity analysis was undertaken where the magnitude of \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$ \overline{\boldsymbol{\alpha}} $$\end{document}α¯ was different across the generating predictors (see Additional file 1 for details), but the results were qualitatively similar as those presented here and so are omitted. </plain></SENT>
</text></p></sec><sec id="Sec8"><title><text><SENT sid="114" pm="."><plain>Simulation design: performance measures </plain></SENT>
</text></title><p><text><SENT sid="115" pm="."><plain>For each iteration within a given simulation scenario, the mean squared error (MSE) between the predicted risk from each aggregate/new model and the actual risk from the generating model were calculated across all samples in the validation set. </plain></SENT>
<SENT sid="116" pm="."><plain>That is, for model m we have, \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$ {\mathrm{MSE}}_{\mathrm{m}}=\frac{1}{n_{validate}}{\displaystyle \sum_{i=1}^{n_{validate}}}{\left({\widehat{\pi}}_{i,m}-{q}_i\right)}^2 $$\end{document}MSEm=1nvalidate∑i=1nvalidateπ^i,m−qi2, where \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$ {\widehat{\pi}}_{i,m} $$\end{document}π^i,m is the predicted risk from model m for observation i in the validation set and q i is the generating model risks for this observation. </plain></SENT>
<SENT sid="117" pm="."><plain>Similarly, the MSE was calculated between the estimated coefficients of each aggregate/new model and the generating coefficients (i.e. \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$ {\mathrm{MSE}}_{\mathrm{m}}=\frac{1}{P}{\displaystyle \sum_{p=1}^P}{\left({\widehat{\beta}}_{p,m}-{\alpha}_{p,M+1}\right)}^2 $$\end{document}MSEm=1P∑p=1Pβ^p,m−αp,M+12, where \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$ {\widehat{\beta}}_{p,m} $$\end{document}β^p,m is the estimated p th coefficient from model m and α p,M + 1 is the p th generating coefficient in the local population). </plain></SENT>
<SENT sid="118" pm="."><plain>Additionally, the calibration and discrimination of each aggregate/new model were calculated in the validation set. </plain></SENT>
<SENT sid="119" pm="."><plain>The calibration was quantified with a calibration intercept and slope, where values of zero and one respectively represent a well-calibrated model [30]. </plain></SENT>
<SENT sid="120" pm="."><plain>Discrimination was evaluated by the area under the ROC curve (AUC). </plain></SENT>
<SENT sid="121" pm="."><plain>All performance measures were averaged across iterations and the empirical standard errors were calculated. </plain></SENT>
</text></p></sec></sec></SecTag><SecTag type="RESULTS"><sec id="Sec9"><title><text><SENT sid="122" pm="."><plain>Results </plain></SENT>
</text></title><sec id="Sec10"><title><text><SENT sid="123" pm="."><plain>Simulated between-population heterogeneity </plain></SENT>
</text></title><p><text><SENT sid="124" pm="."><plain>To gain a practical understanding of the between-population-heterogeneity generated by increasing values of σ, for all simulated parameters the difference between the largest coefficient and smallest coefficient across populations was calculated and summarised (Table 1); such values were compared with corresponding values from the surgical models. </plain></SENT>
<SENT sid="125" pm="."><plain>Coefficient differences over the LES, ESII, STS and German AV represent heterogeneity across cardiac surgery risk models each developed across multiple countries. </plain></SENT>
<SENT sid="126" pm="."><plain>Coefficient differences over these models closely matched those generated with σ = 0.25 or σ = 0.375. </plain></SENT>
<SENT sid="127" pm="."><plain>Conversely, LES and ESII are two models that were developed on very similar cohorts of patients; here, the coefficient differences most closely match those generated by σ = 0.125. </plain></SENT>
<SENT sid="128" pm="."><plain>Similarly, the average standard deviation of the coefficients across the LES, ESII, STS and German AV models was 0.33 (closely matching σ = 0.375), while that between the LES and ESII was 0.26 (closely matching σ = 0.25). </plain></SENT>
<SENT sid="129" pm="."><plain>Together, this suggests that σ values between 0 and 0.375 likely represent the majority of clinical situations, with σ values greater than 0.5 arguably rare in practice.Table 1Summary measures of the difference in generating coefficients values across all simulated populations σ LES, ESII, STS, German AVLES, ESII00.1250.250.3750.50.751Lower Quartilea 00.290.580.861.161.742.310.370.14Mediana 00.310.630.951.271.902.520.570.31Meana 00.320.630.951.271.902.530.700.37Upper Quartilea 00.340.681.031.382.062.740.850.54SDb 00.120.240.360.480.710.950.330.26The values for the LES, ESII, STS and German AV are approximate, since variable definitions vary between CPMs a: values represent summary measures across all iterations of the average difference between the largest coefficient and smallest coefficient across populations b: the average standard deviation (SD) of each coefficient across all populations. </plain></SENT>
<SENT sid="130" pm="."><plain>All values aim to guide the between-population heterogeneity induced through different σ values </plain></SENT>
</text></p></sec><sec id="Sec11"><title><text><SENT sid="131" pm="."><plain>Mean square error </plain></SENT>
</text></title><p><text><SENT sid="132" pm="."><plain>For training set samples of 500 or less and when σ ≤ 0.25, all three aggregation approaches resulted in predicted risks that had smaller mean square error and lowered the variance component of the error compared with redevelopment (Additional file 1: Table S2). </plain></SENT>
<SENT sid="133" pm="."><plain>Similarly, for training sample sizes less than or equal to 500, SR had estimated coefficients with consistently smaller mean square error with lower standard error than the redevelopment approaches, with the exception of the two highest values of σ (Additional file 1: Table S3). </plain></SENT>
<SENT sid="134" pm="."><plain>Conversely, for training samples of 1000 or more, developing a new model by ridge regression provided parameter estimates with at least equivalent MSE to the aggregation methods. </plain></SENT>
</text></p></sec><sec id="Sec12"><title><text><SENT sid="135" pm="."><plain>Model calibration </plain></SENT>
</text></title><p><text><SENT sid="136" pm="."><plain>The calibration intercepts for all the aggregate/new models were not significantly different from zero in the validation set across all simulations (Fig. 2). </plain></SENT>
<SENT sid="137" pm="."><plain>Across all values of σ and for training set sizes smaller than 1000, the calibration slope of the AIC derived model was significantly below one indicating overfitting, while that for ridge regression was higher than one, indicating slight over-shrinkage on the parameters (Fig. 3). </plain></SENT>
<SENT sid="138" pm="."><plain>Conversely, the three aggregate models had a calibration slope not significantly different from one in any scenario, with the exception of PCA in the smallest sample sizes.Fig. 2Calibration Intercept: Calibration intercept in the validation set for SR, PCA and the two newly derived models across all simulation situations. </plain></SENT>
<SENT sid="139" pm="."><plain>The PLS results were nearly identical to SR/PCA and so are omitted for clarity. </plain></SENT>
<SENT sid="140" pm="."><plain>Note: σ = 1 was removed from the plot for clarity since the results quantitatively similar to σ = 0.75 Fig. 3Calibration Slope: Calibration slope in the validation set for SR, PCA and the two newly derived models across all simulation situations. </plain></SENT>
<SENT sid="141" pm="."><plain>The PLS results were nearly identical to SR/PCA and so are omitted for clarity. </plain></SENT>
<SENT sid="142" pm="."><plain>Note: σ = 1 was removed from the plot for clarity since the results quantitatively similar to σ = 0.75 Fig. 4Discrimination: Area under receiver operating characteristic curve (AUC) in the validation set for SR, PCA and the two newly derived models across all scenarios. </plain></SENT>
<SENT sid="143" pm="."><plain>The PLS results were nearly identical to SR/PCA and so are omitted for clarity. </plain></SENT>
<SENT sid="144" pm="."><plain>Note: σ = 1 was removed from the plot for clarity since the results quantitatively similar to σ = 0.75 </plain></SENT>
</text></p></sec><sec id="Sec13"><title><text><SENT sid="145" pm="."><plain>Model discrimination </plain></SENT>
</text></title><p><text><SENT sid="146" pm="."><plain>When σ ≤ 0.125 and for training sets of 250 or fewer, the AUC of SR was significantly higher than that of both redevelopment approaches (Fig. 4). </plain></SENT>
<SENT sid="147" pm="."><plain>Although the 95% confidence intervals overlapped, when σ &lt; 0.25 and the training set was less than 1000 observations, the AUC of the two newly derived models (AIC/ridge) were less than that of the aggregate approaches (Additional file 1: Table S4). </plain></SENT>
<SENT sid="148" pm="."><plain>For instance, when σ = 0, the AUC of SR was higher than that of ridge regression in 988, 968, 821, 498, 56 and 19 out of the 1000 iterations for training set sizes 150, 250, 500, 1000, 5000 and 10000, respectively. </plain></SENT>
<SENT sid="149" pm="."><plain>Hence, given training set samples of less than 500 and very similar populations, SR provides consistently higher AUC than redevelopment by either ridge or backwards selection. </plain></SENT>
</text></p></sec><sec id="Sec14"><title><text><SENT sid="150" pm="."><plain>Modelling strategy recommendations </plain></SENT>
</text></title><p><text><SENT sid="151" pm="."><plain>A framework that compared modelling strategies of redevelopment and aggregation was developed. </plain></SENT>
<SENT sid="152" pm="."><plain>For redevelopment, ridge regression was always recommended over AIC since the former more appropriately accounted for low training set sizes. </plain></SENT>
<SENT sid="153" pm="."><plain>Likewise, all three aggregation approaches performed comparably and so SR was considered here due to the simplicity of implementation. </plain></SENT>
<SENT sid="154" pm="."><plain>Hence, on comparing ridge regression to SR across all simulation scenarios, if one of the models was well calibrated (calibration intercepts and slopes significantly close to zero and one, respectively) and had significantly higher AUC than the other model, then that modelling strategy was recommended. </plain></SENT>
<SENT sid="155" pm="."><plain>Conversely, if both models were well calibrated but the AUCs were not significantly different, then a recommendation of “Either” was given. </plain></SENT>
<SENT sid="156" pm="."><plain>Finally, if one of the models was miscalibrated then the other (calibrated) modelling strategy was recommended. </plain></SENT>
</text></p><p><text><SENT sid="157" pm="."><plain>When the size of the training set was less than 500, then aggregating previously published models by SR was recommended (Table 2). </plain></SENT>
<SENT sid="158" pm="."><plain>Conversely, developing a new model by ridge regression was recommended in situations where σ &gt; 0.375 and the size of the training set was at least 1000 observations. </plain></SENT>
<SENT sid="159" pm="."><plain>Between these scenarios, both aggregation methods and redevelopment methods provided indistinguishable performance. </plain></SENT>
<SENT sid="160" pm="."><plain>Similar recommendations were given when the average event prevalence was increased to 50% (Table 3).Table 2Modelling strategy recommendations when the mean incidence of adverse outcome was 20%σ n train 15025050010005000100000SRSREitherEitherEitherEither0.125SRSREitherEitherEitherEither0.25SRSREitherEitherEitherEither0.375SRSREitherEitherRidgeRidge0.5SRSREitherRidgeRidgeRidge0.75SRSRRidgeRidgeRidgeRidge1.00SRSRRidgeRidgeRidgeRidge Table 3Modelling strategy recommendations when the mean incidence of adverse outcome was 50%σ n train 15025050010005000100000SRSREitherEitherEitherEither0.125SRSREitherEitherEitherEither0.25SRSREitherEitherEitherEither0.375SRSREitherRidgeRidgeRidge0.5SRRidgeRidgeRidgeRidgeRidge0.75RidgeRidgeRidgeRidgeRidgeRidge1.00RidgeRidgeRidgeRidgeRidgeRidge </plain></SENT>
</text></p></sec></sec></SecTag><SecTag type="DISCUSS"><sec id="Sec15"><title><text><SENT sid="161" pm="."><plain>Discussion </plain></SENT>
</text></title><p><text><SENT sid="162" pm="."><plain>This study demonstrates that aggregating multiple published CPMs is a useful derivation strategy, particularly when there are limited data available. </plain></SENT>
<SENT sid="163" pm="."><plain>Stacked regression was a simple yet effective aggregation method, which resulted in predictions and parameter estimates with lowest MSE given low sample sizes and low between-population-heterogeneity. </plain></SENT>
<SENT sid="164" pm="."><plain>These results are consistent with previous studies [9]. </plain></SENT>
<SENT sid="165" pm="."><plain>Conversely, AIC derived models were miscalibrated when the training set sample size was between 150 and 500, confirming that small samples lead to overfitting in new regression estimates [8, 31, 32]. </plain></SENT>
<SENT sid="166" pm="."><plain>Ridge regression, which is a similar concept to parameter shrinkage, mitigated overfitting but was potentially susceptible to slight over-shrinkage. </plain></SENT>
<SENT sid="167" pm="."><plain>Redevelopment only resulted in a model with better performance than the aggregation methods when there was a large amount of training data or the existing CPMs were significantly heterogeneous. </plain></SENT>
</text></p><p><text><SENT sid="168" pm="."><plain>Previous methodological research around incorporating existing CPMs has focussed on updating a single existing model to the new population of interest [7, 8, 10, 33]. </plain></SENT>
<SENT sid="169" pm="."><plain>These techniques range from model recalibration to the additional of new risk factors and have been shown to provide improved performance over deriving new prediction models, especially when only small datasets are available [8]. </plain></SENT>
<SENT sid="170" pm="."><plain>However, updating techniques only adapt one previous model to the current data. </plain></SENT>
<SENT sid="171" pm="."><plain>In this sense, the concept of model aggregation is analogous to meta-analysis since it aims to synthesise all previous research in the development of the CPM. </plain></SENT>
<SENT sid="172" pm="."><plain>Moreover, CPMs often perform poorly in high-risk patients. </plain></SENT>
<SENT sid="173" pm="."><plain>If there are relatively low proportions of high-risk patients in a given population, then the development/ update of a CPM to this population can result in such high-risk, poorly predicted patients becoming more prevalent since parameter estimates occur for the population average. </plain></SENT>
<SENT sid="174" pm="."><plain>In such situations, one should pay close attention to the residuals of the model; machine-learning methods such as Boosting are a formal approach to this. </plain></SENT>
</text></p><p><text><SENT sid="175" pm="."><plain>Since the aim of this study was to examine the benefits of aggregation over independently deriving a CPM, this study compared each approach separately to solely extract the benefit of either method. </plain></SENT>
<SENT sid="176" pm="."><plain>However, meta-analysis methods that simultaneously aggregate and redevelop CPMs have been proposed [18, 34, 35]; utilising existing CPMs, expert knowledge and new data optimally requires further research. </plain></SENT>
<SENT sid="177" pm="."><plain>For instance, risk factors may not be common across existing CPMs, which could lead to bias if one is interested in simultaneously aggregating and redeveloping CPMs in the local population [36]. </plain></SENT>
<SENT sid="178" pm="."><plain>Previous methodology of CPM meta-analysis with individual patient data has largely been limited to assuming that models share similar risk predictors [10, 18]. </plain></SENT>
<SENT sid="179" pm="."><plain>Conversely, SR, PCA and PLS relax this assumption [9]. </plain></SENT>
<SENT sid="180" pm="."><plain>Indeed, the simulation design of this study allowed the existing CPMs to be heterogeneous in their risk predictor set. </plain></SENT>
</text></p><p><text><SENT sid="181" pm="."><plain>Nevertheless, there are potential problems of aggregating CPMs that require attention. </plain></SENT>
<SENT sid="182" pm="."><plain>Firstly, each existing CPM aims to predict the same outcome and most include very similar subset of predictors, thus inducing a high level of correlation between the multiple CPMs. </plain></SENT>
<SENT sid="183" pm="."><plain>Although the weights in SR are restricted to be non-negative to avoid situations of negative coefficients caused by inclusion of two correlated models, further work examining the collinearity issues is required [10]. </plain></SENT>
<SENT sid="184" pm="."><plain>Secondly, differences in risk factor definitions between existing CPMs could potentially weaken the performance of SR, PCA or PLS. </plain></SENT>
<SENT sid="185" pm="."><plain>The current study aimed to replicate this practical limitation by generating predictors within clusters of correlated variables; here, given a moderate degree of correlation between the multiple similarly defined risk factors, the aggregation methods still performed well. </plain></SENT>
<SENT sid="186" pm="."><plain>Finally, datasets across populations frequently collect different variables, potentially meaning a variable included in an existing CPM is not available in the local population. </plain></SENT>
<SENT sid="187" pm="."><plain>In such circumstances of systematically missing covariates, it is unclear how one should calculate the linear predictor for patients in the new local population [37]. </plain></SENT>
<SENT sid="188" pm="."><plain>If systematically missing risk factors are not handled appropriately, then the aggregate CPM could be biased. </plain></SENT>
</text></p><p><text><SENT sid="189" pm="."><plain>The main strength of this work is that we perform a simulation study under a range of realistic scenarios and consider multiple performance measures, thereby allowing a comprehensive and systematic examination of the aggregation approaches. </plain></SENT>
<SENT sid="190" pm="."><plain>Conversely, the main limitation is that we simulate only a crude reflection of real between-population-heterogeneity. </plain></SENT>
<SENT sid="191" pm="."><plain>Over-arching variance of model parameters does not necessarily reflect the complex differences in data-generating processes that may vary between populations. </plain></SENT>
<SENT sid="192" pm="."><plain>However, without a comprehensive set of joint probability distributions for the covariates of a given model, accurately modelling population heterogeneity is difficult to achieve. </plain></SENT>
<SENT sid="193" pm="."><plain>Hence, confirmation of our findings will be required from studies in observational datasets. </plain></SENT>
<SENT sid="194" pm="."><plain>A further limitation is that publication bias is known to impact prognostic research [38], but its effects were not analysed in this study; such bias would lead to overestimation of aggregated regression coefficients. </plain></SENT>
<SENT sid="195" pm="."><plain>Finally, the aggregation methods assume that each population is a random sample from an over-arching common population. </plain></SENT>
<SENT sid="196" pm="."><plain>The data-generating mechanisms in this simulation directly matched this assumption by simulating generating model coefficients as a random sample from a common distribution. </plain></SENT>
<SENT sid="197" pm="."><plain>Similarly, the distributions of the risk predictors were assumed the same between populations. </plain></SENT>
</text></p><p><text><SENT sid="198" pm="."><plain>Overall, the current work suggests a framework of modelling strategy when developing a model for a local/ defined population. </plain></SENT>
<SENT sid="199" pm="."><plain>In practice, an estimate of the between-population-heterogeneity could be approximated by examining the differences in coefficients between existing CPMs, exploiting clinical knowledge between networks of modelling teams and by examining the distribution of the linear predictors between populations [39]. </plain></SENT>
<SENT sid="200" pm="."><plain>In many practical scenarios, the variability between populations will be low; thus the situations of σ = 0 to σ = 0.375 in the current study likely closely represent clinical practice. </plain></SENT>
<SENT sid="201" pm="."><plain>If the size of the local data is &lt;10% of that the existing CPMs were derived on, and if the multiple populations share clinically similar demographic and procedural characteristics, then we recommend aggregating existing models. </plain></SENT>
<SENT sid="202" pm="."><plain>Secondly, if the size of local data matches or exceeds that of existing model derivations, then deriving a new CPM could be appropriate, although the existing CPMs could still provide useful prior information about likely covariate-outcome associations. </plain></SENT>
<SENT sid="203" pm="."><plain>Finally, in all other circumstances, one should consider either aggregation, redevelopment or a combination of the two [18]. </plain></SENT>
<SENT sid="204" pm="."><plain>Here, the sample sizes relative to the number of predictors per event [31], the estimated population heterogeneity, the quality of the existing CPMs and the availability of variables should drive the chosen method. </plain></SENT>
</text></p></sec></SecTag><SecTag type="CONCL"><sec id="Sec16"><title><text><SENT sid="205" pm="."><plain>Conclusions </plain></SENT>
</text></title><p><text><SENT sid="206" pm="."><plain>Aggregating existing CPMs is beneficial in the development of a CPM for healthcare predictions in defined populations. </plain></SENT>
<SENT sid="207" pm="."><plain>In the majority of situations, modellers should consider existing CPMs before developing models anew, with their aggregation potentially providing optimal performance given low sample sizes relative to that of previous model derivations. </plain></SENT>
<SENT sid="208" pm="."><plain>Deriving a new CPM independent of previous research was only recommended in the unusual situation of having more data available than used to derive existing models, or a local context that is markedly different to those of existing CPMs. </plain></SENT>
</text></p></sec></SecTag></body><back><SecTag type="APPENDIX"><app-group><app id="App1"><sec id="Sec17"><title>Additional file</title><p>
<media position="anchor" xlink:href="12874_2016_277_MOESM1_ESM.docx" id="MOESM1"><label>Additional file 1:</label><caption><p><text><SENT sid="209" pm="."><plain>Details of the Partial Least Squared regression methodology, additional details of the simulation design, additional tables and the simulation R code. </plain></SENT>
<SENT sid="210" pm="."><plain>(DOCX 49 kb) </plain></SENT>
</text></p></caption></media>
</p></sec></app></app-group></SecTag><SecTag type="ABBR"><glossary><title>Abbreviations</title><def-list><def-item><term>CPM</term><def><p>Clinical prediction model</p></def></def-item><def-item><term>ESII</term><def><p>EuroSCORE II</p></def></def-item><def-item><term>German AV</term><def><p>German Aortic Valve Model</p></def></def-item><def-item><term>LES</term><def><p>Logistic EuroSCORE</p></def></def-item><def-item><term>MSE</term><def><p>Mean Square Error</p></def></def-item><def-item><term>PCA</term><def><p>Principal component analysis</p></def></def-item><def-item><term>PLS</term><def><p>Partial least squares</p></def></def-item><def-item><term>SR</term><def><p>Stacked regression</p></def></def-item></def-list></glossary></SecTag><SecTag type="AUTH_CONT"><ack><title>Acknowledgements</title><p>Not applicable.</p><sec id="FPar1"><title>Funding</title><p>This work was funded by the Medical Research Council through the Health e-Research Centre, University of Manchester [MR/K006665/1].</p></sec><sec id="FPar2"><title>Availability of data and material</title><p>The data on which the conclusions of this manuscript rely can be reproduced using the R code available in the online Additional file <xref rid="MOESM1" ref-type="media">1</xref>.</p></sec><sec id="FPar3"><title>Authors’ contributions</title><p>GPM and MS designed the study and drafted the initial version of the manuscript. GPM wrote the simulation R code. GPM, MAM, NP, IB and MS analysed/interpreted the results and revised the manuscript critically for important intellectual content. All of the authors approved the final version and agreed to be accountable for all aspects of the work.</p></sec><sec id="FPar4"><title>Competing interests</title><p>The authors declare that they have no competing interests.</p></sec><sec id="FPar5"><title>Consent for publication</title><p>Not applicable.</p></sec><sec id="FPar6"><title>Ethics approval and consent to participate</title><p>Not applicable.</p></sec></ack></SecTag><SecTag type="REF"><ref-list id="Bib1"><title>References</title><ref id="CR1"><text><SENT sid="211" pm="."><plain>1.KappenTHVergouweYvan KleiWAvan WolfswinkelLKalkmanCJMoonsKGMAdaptation of Clinical Prediction Models for Application in Local SettingsMed Decis Mak201232E1E1010.1177/0272989X12439755 </plain></SENT>
</text></ref><ref id="CR2"><text><SENT sid="212" pm="."><plain>2.DamenJAAGHooftLSchuitEDebrayTPACollinsGSTzoulakiILassaleCMSiontisGCMChiocchiaVRobertsCSchlüsselMMGerrySBlackJAHeusPvan der SchouwYTPeelenLMMoonsKGMPrediction models for cardiovascular disease risk in the general population: systematic reviewBMJ2016353i241610.1136/bmj.i2416<?supplied-pmid 27184143?>27184143 </plain></SENT>
</text></ref><ref id="CR3"><text><SENT sid="213" pm="."><plain>3.AltmanDGVergouweYRoystonPMoonsKGMPrognosis and prognostic research: validating a prognostic modelBMJ2009338b60510.1136/bmj.b605<?supplied-pmid 19477892?>19477892 </plain></SENT>
</text></ref><ref id="CR4"><text><SENT sid="214" pm="."><plain>4.RoystonPMoonsKGMAltmanDGVergouweYPrognosis and prognostic research: Developing a prognostic modelBMJ2009338b60410.1136/bmj.b604<?supplied-pmid 19336487?>19336487 </plain></SENT>
</text></ref><ref id="CR5"><text><SENT sid="215" pm="."><plain>5.MoonsKGMAltmanDGVergouweYRoystonPPrognosis and prognostic research: application and impact of prognostic models in clinical practiceBMJ2009338b60610.1136/bmj.b606<?supplied-pmid 19502216?>19502216 </plain></SENT>
</text></ref><ref id="CR6"><text><SENT sid="216" pm="."><plain>6.RileyRDEnsorJSnellKIEDebrayTPAAltmanDGMoonsKGMCollinsGSExternal validation of clinical prediction models using big datasets from e-health records or IPD meta-analysis: opportunities and challengesBMJ2016353i314010.1136/bmj.i3140<?supplied-pmid 27334381?>27334381 </plain></SENT>
</text></ref><ref id="CR7"><text><SENT sid="217" pm="."><plain>7.JanssenKJMMoonsKGMKalkmanCJGrobbeeDEVergouweYUpdating methods improved the performance of a clinical prediction model in new patientsJ Clin Epidemiol200861768610.1016/j.jclinepi.2007.04.018<?supplied-pmid 18083464?>18083464 </plain></SENT>
</text></ref><ref id="CR8"><text><SENT sid="218" pm="."><plain>8.SteyerbergEWBorsboomGJJMvan HouwelingenHCEijkemansMJCHabbemaJDFValidation and updating of predictive logistic regression models: a study on sample size and shrinkageStat Med2004232567258610.1002/sim.1844<?supplied-pmid 15287085?>15287085 </plain></SENT>
</text></ref><ref id="CR9"><text><SENT sid="219" pm="."><plain>9.DebrayTPAKoffijbergHNieboerDVergouweYSteyerbergEWMoonsKGMMeta-analysis and aggregation of multiple published prediction modelsStat Med2014332341236210.1002/sim.6080<?supplied-pmid 24752993?>24752993 </plain></SENT>
</text></ref><ref id="CR10"><text><SENT sid="220" pm="."><plain>10.SuT-LJakiTHickeyGLBuchanISperrinMA review of statistical updating methods for clinical prediction modelsStat Methods Med Res2016 </plain></SENT>
</text></ref><ref id="CR11"><text><SENT sid="221" pm="."><plain>11.AltmanDGPrognostic Models: A Methodological Framework and Review of Models for Breast CancerCancer Invest20092723524310.1080/07357900802572110<?supplied-pmid 19291527?>19291527 </plain></SENT>
</text></ref><ref id="CR12"><text><SENT sid="222" pm="."><plain>12.NashefSAMRoquesFSharplesLDNilssonJSmithCGoldstoneARLockowandtUEuroSCORE IIEur J Cardio-Thoracic Surg20124173474510.1093/ejcts/ezs043 </plain></SENT>
</text></ref><ref id="CR13"><text><SENT sid="223" pm="."><plain>13.RoquesFThe logistic EuroSCOREEur Heart J20032488210.1016/S0195-668X(02)00799-6 </plain></SENT>
</text></ref><ref id="CR14"><text><SENT sid="224" pm="."><plain>14.O’BrienSMShahianDMFilardoGFerrarisVAHaanCKRichJBNormandS-LTDeLongERShewanCMDokholyanRSPetersonEDEdwardsFHAndersonRPThe Society of Thoracic Surgeons 2008 Cardiac Surgery Risk Models: Part 2—Isolated Valve SurgeryAnn Thorac Surg200988S23S4210.1016/j.athoracsur.2009.05.056<?supplied-pmid 19559823?>19559823 </plain></SENT>
</text></ref><ref id="CR15"><text><SENT sid="225" pm="."><plain>15.ShahianDMO’BrienSMFilardoGFerrarisVAHaanCKRichJBNormandS-LTDeLongERShewanCMDokholyanRSPetersonEDEdwardsFHAndersonRPThe Society of Thoracic Surgeons 2008 Cardiac Surgery Risk Models: Part 3—Valve Plus Coronary Artery Bypass Grafting SurgeryAnn Thorac Surg200988S43S6210.1016/j.athoracsur.2009.05.055<?supplied-pmid 19559824?>19559824 </plain></SENT>
</text></ref><ref id="CR16"><text><SENT sid="226" pm="."><plain>16.KottingJSchillerWBeckmannASchaferEDoblerKHammCVeitCWelzAGerman Aortic Valve Score: a new scoring system for prediction of mortality related to aortic valve procedures in adultsEur J Cardio-Thoracic Surg20134397197710.1093/ejcts/ezt114 </plain></SENT>
</text></ref><ref id="CR17"><text><SENT sid="227" pm="."><plain>17.BreimanLStacked RegressionMach Learn1996244964 </plain></SENT>
</text></ref><ref id="CR18"><text><SENT sid="228" pm="."><plain>18.DebrayTPAKoffijbergHVergouweYMoonsKGMSteyerbergEWAggregating published prediction models with individual participant data: a comparison of different approachesStat Med2012312697271210.1002/sim.5412<?supplied-pmid 22733546?>22733546 </plain></SENT>
</text></ref><ref id="CR19"><text><SENT sid="229" pm="."><plain>19.HotellingHAnalysis of a complex of statistical variables into principal componentsJ Educ Psychol19332441744110.1037/h0071325 </plain></SENT>
</text></ref><ref id="CR20"><text><SENT sid="230" pm="."><plain>20.MerzCJPazzaniMJA Principal Components Approach to Combining Regression EstimatesMach Learn19993693210.1023/A:1007507221352 </plain></SENT>
</text></ref><ref id="CR21"><text><SENT sid="231" pm="."><plain>21.VergouweYSteyerbergEWEijkemansMJCHabbemaJDFSubstantial effective sample sizes were required for external validation studies of predictive logistic regression modelsJ Clin Epidemiol20055847548310.1016/j.jclinepi.2004.06.017<?supplied-pmid 15845334?>15845334 </plain></SENT>
</text></ref><ref id="CR22"><text><SENT sid="232" pm="."><plain>22.CollinsGSOgundimuEOAltmanDGSample size considerations for the external validation of a multivariable prognostic model: a resampling studyStat Med20163521422610.1002/sim.6787<?supplied-pmid 26553135?>26553135 </plain></SENT>
</text></ref><ref id="CR23"><text><SENT sid="233" pm="."><plain>23.PeekNArtsDGTBosmanRJvan der VoortPHJde KeizerNFExternal validation of prognostic models for critically ill patients required substantial sample sizesJ Clin Epidemiol20076049150110.1016/j.jclinepi.2006.08.011<?supplied-pmid 17419960?>17419960 </plain></SENT>
</text></ref><ref id="CR24"><text><SENT sid="234" pm="."><plain>24.AustinPCSteyerbergEWEvents per variable (EPV) and the relative performance of different strategies for estimating the out-of-sample validity of logistic regression modelsStat Methods Med Res2014 </plain></SENT>
</text></ref><ref id="CR25"><text><SENT sid="235" pm="."><plain>25.R Core Team R: R: A Language and Environment for Statistical Computing. </plain></SENT>
<SENT sid="236" pm="."><plain>R Foundation for Statistical Computing 2016. </plain></SENT>
<SENT sid="237" pm="."><plain>[R Foundation for Statistical Computing] </plain></SENT>
</text></ref><ref id="CR26"><text><SENT sid="238" pm="."><plain>26.RobinXTurckNHainardATibertiNLisacekFSanchezJ-CMüllerMpROC: an open-source package for R and S+ to analyze and compare ROC curvesBMC Bioinformatics2011127710.1186/1471-2105-12-77<?supplied-pmid 21414208?>21414208 </plain></SENT>
</text></ref><ref id="CR27"><text><SENT sid="239" pm="."><plain>27.BertrandFMeyerNMaumy-BertrandMPartial Least Squares Regression for Generalized Linear Models2014 </plain></SENT>
</text></ref><ref id="CR28"><text><SENT sid="240" pm="."><plain>28.FriedmanJHastieTTibshiraniRRegularization Paths for Generalized Linear Models via Coordinate DescentJ Stat Softw20103312210.18637/jss.v033.i01<?supplied-pmid 20808728?>20808728 </plain></SENT>
</text></ref><ref id="CR29"><text><SENT sid="241" pm="."><plain>29.SperrinMJakiTRecovering Independent Associations in Genetics: A ComparisonJ Comput Biol20121997898710.1089/cmb.2011.0141<?supplied-pmid 22876789?>22876789 </plain></SENT>
</text></ref><ref id="CR30"><text><SENT sid="242" pm="."><plain>30.CoxDTwo further applications of a model for binary regressionBiometrika19584556256510.1093/biomet/45.3-4.562 </plain></SENT>
</text></ref><ref id="CR31"><text><SENT sid="243" pm="."><plain>31.SteyerbergEStepwise Selection in Small Data Sets A Simulation Study of Bias in Logistic Regression AnalysisJ Clin Epidemiol19995293594210.1016/S0895-4356(99)00103-1<?supplied-pmid 10513756?>10513756 </plain></SENT>
</text></ref><ref id="CR32"><text><SENT sid="244" pm="."><plain>32.SteyerbergEWEijkemansMJCHarrellFEHabbemaJDFPrognostic Modeling with Logistic Regression Analysis: In Search of a Sensible Strategy in Small Data SetsMed Decis Mak200121455610.1177/0272989X0102100106 </plain></SENT>
</text></ref><ref id="CR33"><text><SENT sid="245" pm="."><plain>33.TollDBJanssenKJMVergouweYMoonsKGMValidation, updating and impact of clinical prediction rules: A reviewJ Clin Epidemiol2008611085109410.1016/j.jclinepi.2008.04.008<?supplied-pmid 19208371?>19208371 </plain></SENT>
</text></ref><ref id="CR34"><text><SENT sid="246" pm="."><plain>34.SteyerbergEWEijkemansMJCVan HouwelingenJCLeeKLHabbemaJDFPrognostic models based on literature and individual patient data in logistic regression analysisStat Med20001914116010.1002/(SICI)1097-0258(20000130)19:2&lt;141::AID-SIM334&gt;3.0.CO;2-O<?supplied-pmid 10641021?>10641021 </plain></SENT>
</text></ref><ref id="CR35"><text><SENT sid="247" pm="."><plain>35.RileyRDSimmondsMCLookMPEvidence synthesis combining individual patient data and aggregate data: a systematic review identified current practice and possible methodsJ Clin Epidemiol200760431439<?supplied-pmid 17419953?>17419953 </plain></SENT>
</text></ref><ref id="CR36"><text><SENT sid="248" pm="."><plain>36.YoneokaDHenmiMSawadaNInoueMSynthesis of clinical prediction models under different sets of covariates with one individual patient dataBMC Med Res Methodol20151510110.1186/s12874-015-0087-x<?supplied-pmid 26585325?>26585325 </plain></SENT>
</text></ref><ref id="CR37"><text><SENT sid="249" pm="."><plain>37.HeldUKesselsAGarcia AymerichJBasagañaXter RietGMoonsKGMPuhanMAMethods for Handling Missing Variables in Risk Prediction ModelsAm J Epidemiol2016<?supplied-pmid 27630143?>27630143 </plain></SENT>
</text></ref><ref id="CR38"><text><SENT sid="250" pm="."><plain>38.HemingwayHRileyRDAltmanDGTen steps towards improving prognosis researchBMJ2009339b418410.1136/bmj.b4184<?supplied-pmid 20042483?>20042483 </plain></SENT>
</text></ref><ref id="CR39"><text><SENT sid="251" pm="."><plain>39.DebrayTPAVergouweYKoffijbergHNieboerDSteyerbergEWMoonsKGMA new framework to enhance the interpretation of external validation studies of clinical prediction modelsJ Clin Epidemiol20156827928910.1016/j.jclinepi.2014.06.018<?supplied-pmid 25179855?>25179855 </plain></SENT>
</text></ref></ref-list></SecTag></back></article>
